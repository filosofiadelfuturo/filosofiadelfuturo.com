---
layout: post
title: "Inteligencia artificial: la nueva escuela"
date: 2020-02-01
authors: "Santiago López Gagliano"
excerpt: "Nueva inteligencia artificial, robótica y corporalidad"
tags: [ia]
comments: true
---
[En la nota anterior](https://futurephilosophy.github.io/ia-vieja-escuela/) empezamos a contarte cuándo, dónde, y un poco acerca de cómo empezaron a construirse las primeras arquitecturas que le daban cuerpo al viejo sueño de construir una máquina que manifieste una inteligencia como la nuestra: la inteligencia artificial simbólica -o GOFAI-, que comenzó a mediados de los 50, se extendió a lo largo de los 60 y en los 70 empezó a manifestar sus limitaciones. También vimos la paradoja de Moravec que nos enseña mucho no sólo acerca de cuáles son las complicaciones a la hora de producir artificialmente una inteligencia como la nuestra, sino que también nos da pautas acerca de cómo autopercibimos nuestras habilidades, a qué tipos de capacidades solemos atribuirle complejidad e inteligencia, y cuales damos por sentadas.


Con todo esto sobre la mesa, a mediados de los los 80 empezó a surgir una nueva camada de desarrolladorxs que inspirándose en los éxitos y fracasos de la “vieja escuela de la IA”, compusieron un nuevo núcleo de ideas e implementaciones tecnológicas que le han dado a llamar “[nueva IA](https://es.m.wikipedia.org/wiki/Nouvelle_AI)”. Este enfoque se propuso construir robots que, en vez de operar en micromundos limitados, pudieran afrontar las dificultades del mundo real, para lo cual, a diferencia de la GOFAI, dejaron de perseguir el diseño de inteligencia artificial como la manipulación de símbolos complejos, para entenderla más bien como la implementación de un conjunto de reglas muy sencillas que le permiten a un agente adaptarse de manera rápida y flexible. La premisa es que un robot, en vez de elaborar modelos internos de su mundo circundante, se base permanentemente en sus sensores que le muestran “lo que está ahí afuera”, actualizándose de forma constante a partir de la información recogida por ellos y estableciendo procesos que sean lo más minimalistas posibles, para poder adaptarse de forma plástica y dinámica al mundo circundante. Ya no se trata de que el robot  produzca modelos que “reemplacen” al mundo: es el mundo el que ofrece este modelo. Lo que tendrá que hacer un agente inteligente es adaptarse a él a partir de sus posibilidades físicas y computacionales.


Para comprender un poco de qué se trató este cambio de dirección, pensemos en cuáles eran las inspiraciones que tomaban del mundo biológico: mientras que los desarrolladores de la GOFAI tenían el norte puesto en las operaciones lógico-matemáticas que un humano adulto es capaz de realizar, la nueva IA se fija en los comportamientos que característicamente vemos en insectos, como evitar obstáculos en movimiento, o trepar y agarrar objetos. Recordemos la paradoja de Moravec: aquellas capacidades más nuevas en el desarrollo evolutivo eran el punto de partida de la GOFAI; en cambio, la nueva IA decide seguir los pasos de la naturaleza, y empezar con los comportamientos más antiguos de la historia evolutiva. Dicho en otras palabras: la vieja IA empieza de “[arriba hacia abajo](https://es.m.wikipedia.org/wiki/Top-down_y_bottom-up)”, mientras que la nueva IA, de “[abajo hacia arriba](https://es.m.wikipedia.org/wiki/Top-down_y_bottom-up)”. Con esta estrategia se busca reconstruir los procesos que dan lugar a la inteligencia, en vez de dirigirse directamente hacia ella.


Algunos de los representantes de esta camada fueron [Barbara Webb](https://www.edinburgh-robotics.org/academics/barbara-webb), una de las pioneras de la Biorobótica, y [Rodney Brooks](https://people.csail.mit.edu/brooks/), quien entre otras cosas fue el diseñador del prototipo de las aspiradoras-robot [Roomba](https://es.m.wikipedia.org/wiki/Roomba) y formó parte del diseño del [Róver Sojourner](https://spaceplace.nasa.gov/mars-sojourner/sp/), un robot que pisó el suelo de Marte en 1997 como parte programa [Discovery](https://www.nasa.gov/planetarymissions/discovery.html) de la NASA.  Veamos de cerca algunos de los robots craneados por este último en el laboratorio de Inteligencia Artificial de MIT: [Allen](http://www.alanturing.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI11.html) -llamado así por [Allen Newell](https://www.britannica.com/biography/Allen-Newell)-  estaba compuesto por doce sondas ultrasónicas, que eran sus sensores principales. Estos sensores proporcionaban mediciones de profundidad a cada segundo. Esta información a su vez era capturada por tres módulos que eran independientes entre sí, pero cuya funcionalidad se encontraba relacionada. Uno de estos módulos se encargaba de que el robot evite colisionar con objetos, el segundo permitía que el robot deambulara, y el tercero garantizaba que el robot avanzara hacia objetos lejanos una vez que eran detectados por los sensores. Con este equipamiento, Allen logró interactuar con entornos complejos de forma exitosa. Si bien es cierto que su comportamiento distaba de igualar a las habilidades que exhibe un insecto biológico, significó un punto a favor de la idea de ir construyendo máquinas basadas en comportamientos elementales, que marquen una vía incremental de complejidad. Por otro lado, esto se logró sin apelar a representaciones explícitas del mundo; las operaciones computacionales de este robot no estaban puestas en construir un modelo interno del mundo circundante, si no en tener como referencia la data recibida por los sensores y hacerla interactuar con módulos productores de comportamiento de la forma más directa posible. De este modo, el robot puede ir actualizando su accionar en función de las novedades que le ofrece su entorno.


Otro robot construido a partir de estas premisas fue [COG](https://es.m.wikipedia.org/wiki/COG), un hito en la historia de los robots humanoides. A diferencia del ejemplo anterior, el proyecto COG tenía como target ciertas capacidades atribuibles a la inteligencia humana, pero lo hacía siguiendo el enfoque “desde abajo hacia arriba”. Es decir, buscando que la cognición emerja a partir de una serie de actividades más elementales, y con el menor peso posible en la elaboración de representaciones internas. COG disponía de cuatro estructuras sensibles al sonido, dos cámaras montadas en lo que vendría a ser su “cabeza”, detectores de tensión, calor y corriente, y conductores de energía eléctrica que le proporcionaban información táctil y propioceptiva. Sus mecanismos de movimiento constaban de un torso capaz de inclinarse y torcerse, un brazo y una mano. Una sofisticada integración entre sensores de distintas modalidades y los mecanismos de movimientos le permitió a COG emular algunos de los aspectos ligados al aprendizaje de categorías y de formación de conceptos que se observan en bebés humanos. Estos últimos aprenden de su entorno a partir de actividades motoras autogeneradas - como agarrar, empujar, jalar y chupar - que actúan como complemento para el procesamiento neuronal, guiando al flujo de información sensorial que reciben; de manera análoga, COG detectaba patrones rítmicos individuales y asociaba señales periódicas gracias a la implementación de un algoritmo de enlace. A partir de dichos enlaces, COG podía aprender sobre sus propias partes del cuerpo, pudiendo incluso dar muestras de reconocer la imagen de su propio brazo en el espejo.


Son muchos los ámbitos de aplicación que la nueva IA tiene y ha tenido. Algunos de ellos son la agricultura, la automatización laboral, los servicios de salud, el desarrollo militar, y tareas domésticas, entre otros. Sin lugar a dudas, veremos muchas más aplicaciones en los próximos años y en niveles que muy posiblemente nos sorprenderían hoy por hoy. Y aunque la cultura pop (con Hollywood a la cabeza) en muchos casos nos ha educado para tenerle cierta fobia a este campo de desarrollo tecnológico, quizás ya sería hora de que le perdamos el miedo a los robots, comprendiendo cuales son los principios de sus diseños, sus posibilidades, sus limitaciones y cuál podría ser nuestra incidencia en garantizar que estos escenarios distópicos no se produzcan. Ciertamente, una mirada frívola, acrítica y tecnofóbica no darán como resultado una respuesta efectiva a este problema.

---
##### En esta nota continuamos con nuestra edición especial de verano, dedicada a la historia de la inteligencia artificial, esta vez con las nuevas tendencias que le siguieron a su paradigma inicial en la conferencia de Dartmouth. Te dejamos algunos links para ampliar la lectura:


##### Pfeifer, R. & Bongard, J (2007). [How the Body Shapes the Way We Think A New View of Intelligence](https://mitpress.mit.edu/books/how-body-shapes-way-we-think).  MIT Press

##### Este libro es una referencia ineludible para comprender aspectos de biorobótics y sus implicaciones filosóficas. También ofrece una taxonomía bastante completa de los tipos de robots que en un futuro no muy lejano podrían acompañarnos en nuestro día a día.


##### Brooks, R (1999). [Cambrian Intelligence: The Early History of the New AI](https://mitpress.mit.edu/books/cambrian-intelligence). MIT Press.

##### Todas las ideas principales acerca de la nueva IA están desarrolladas en este compendio de papers escritos por Rodney Brooks. En el podemos observar los primeros pasos de este enfoque, y su ulterior evolución.


##### Clark, A (2007). [Supersizing the Mind](https://global.oup.com/academic/product/supersizing-the-mind-9780195333213?cc=us&lang=en&). MIT Press.

##### Esta obra filosófica integra aspectos de ciencias cognitivas, filosofía de la mente, neurociencias e inteligencia artificial en una perspectiva integral acerca de la cognición humana en particular, y animal en general. Algunos casos de la robótica del paradigma de la nueva IA le sirven al autor para ilustrar ejemplos y elaborar argumentos en favor de sus tesis.


##### Webb, B (2001). [Biorobotics: Methods and Applications](https://www.aaai.org/Press/Books/webb.php). AAAI Pres.

##### Otra minuciosa exploración en el mundo de la biorobótica por parte de Barbara Webb, una de las maestras en el área. En esta obra demuestra cómo la robótica puede funcionar para construir modelos científicos que expliquen el comportamiento de animales biológicos.
