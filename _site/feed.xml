<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-05-28T18:32:55+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Filosofía del Futuro</title><subtitle>Colectivo interdisciplinario para el desarrollo y la divulgación de la Filosofía del Futuro</subtitle><entry><title type="html">La propiedad y los datos</title><link href="http://localhost:4000/propiedad-datos/" rel="alternate" type="text/html" title="La propiedad y los datos" /><published>2020-04-18T00:00:00+02:00</published><updated>2020-04-18T00:00:00+02:00</updated><id>http://localhost:4000/propiedad-datos</id><content type="html" xml:base="http://localhost:4000/propiedad-datos/">&lt;p&gt;Interactuar es intercambiar información. Cuando lo hacemos con gente tenemos las cosas bastante claras. La mayoría de nosotrxs aprendió, con los años, cómo sonreír para ocultar que hay alguien a quien no nos bancamos, qué palabras usar para exponer cuánto amamos, cuánto dicen nuestros ojos si mentimos o cómo sentarnos en clase para demostrar concentración. Sabemos, también, que en general del otro lado no hay alguien tomando nota de cada detalle. Estoy bastante seguro de que nadie con quien haya charlado tiene un registro de todo mi historial de acciones, palabras y movimientos, y más seguro aún de que no tienen esas mismas anotaciones sobre una cantidad de personas suficiente, ni el tiempo de estudio necesario, como para poder sacar conclusiones generales sobre la relación entre qué está pensando y cómo se muestra una persona. Como somos bichos sociales, sabemos ser transparentes y opacos. Del otro lado hay gente que en general no puede ver muchísimo más que eso que queremos mostrar, o que al menos no le dedica el tiempo, la atención ni la construcción necesaria de teoría predictiva. Nuestra vida social, nuestra libertad, nuestra identidad personal e incluso nuestra dignidad se sostienen a partir del moderado control que podemos tener sobre qué mostramos y qué no. El cimiento de nuestra vida pública es la privacidad personal.&lt;/p&gt;

&lt;p&gt;Sabemos que con el celular, la computadora, y hasta con algunos electrodomésticos la cosa es muy distinta. Ni es un área de interacción de la que somos nativos, ni tenemos automatizado el proceso de cuidar bien qué comunicamos, ni la interacción está tan espaciada en el tiempo. Y más aún, todos estos dispositivos hacen lo que las personas no: son canales de información que van derechito a servidores de empresas de informática, donde quedan registros rigurosos y sí existen las tecnologías de cómputo suficientemente poderosas como para hacer los estudios comparativos que permitirían que se sepa mucho más de mí de lo que quiero mostrar.&lt;/p&gt;

&lt;p&gt;¿Por qué acumular toda esa cantidad de información? El costo de mantener esas comunicaciones, bases de datos y centros de cómputo es altísimo. Ningún comité directivo admitiría tales costos si fuera cosa de satisfacer un gusto por el chusmerío. El meollo de la cuestión es que es una herramienta sumamente productiva. Es, con todas las letras, una forma de capital, probablemente mucho más útil de lo que hoy podamos imaginar. Ya discutimos sobre &lt;a href=&quot;https://filosofiadelfuturo.com/pandemia-ideas/&quot;&gt;cómo puede usarse para controlar la transmisión de discursos en redes sociales&lt;/a&gt; o para &lt;a href=&quot;https://filosofiadelfuturo.com/pandemia-ideas/&quot;&gt;evitar el caos que la pandemia actual está causando&lt;/a&gt;. Indiscutiblemente es una herramienta logística fantástica, un instrumento para la vigilancia sin precedentes, un campo de estudios excelente para el marketing, y un pantallazo de la humanidad que podría dar insights para la sociología, la psicología y hasta la inteligencia artificial, respecto de los cuales los adjetivos probablemente me quedarían cortos.&lt;/p&gt;

&lt;p&gt;Por un lado, &lt;a href=&quot;https://filosofiadelfuturo.com/decada-del-siglo/&quot;&gt;tanto poder en tan pocas manos podría poner en riesgo la democracia&lt;/a&gt; y el &lt;a href=&quot;https://filosofiadelfuturo.com/delitos-proxy/&quot;&gt;mismísimo estado de derecho&lt;/a&gt;, y ni hablar del costo de oportunidad que implica que no podamos hacer usufructo público del mismo. Por el otro, distribuir sin más ese poder da por tierra a toda esa privacidad que quisiéramos tener. La libertad, la democracia y la igualdad parecen consignas muy abstractas si se oponen a lo concreto de la imagen de la pérdida completa de nuestra privacidad, de la desnudez absoluta, de que quien quisiera pudiera acceder a tanta información tan mía de qué dije, qué hice y dónde estuve, tanto en línea como en el mundo.&lt;/p&gt;

&lt;p&gt;La primera salida del dilema que nos puede venir a la cabeza es la ludista, de prender fuego cada uno de esos servidores. La realidad es que por un lado eso destruiría una enorme porción de las cosas que hoy nos gustan y del modo en que nos comunicamos y vivimos, y por otro lado destruiría quizás la herramienta más poderosa que construimos hasta ahora, antes siquiera de que aprendiéramos a usarla para el bien.&lt;/p&gt;

&lt;p&gt;En la tradición marxista, desde el propio &lt;a href=&quot;https://www.marxists.org/espanol/m-e/1840s/48-manif.htm&quot;&gt;manifiesto&lt;/a&gt;, se menciona un problema similar al que vemos acá sobre los datos. Es la distinción entre propiedad privada y propiedad personal. La idea es distinguir dos aspectos de la propiedad, respectivamente: uno inevitable y hasta deseable, y otro que es el que produce injusticia y explotación, y debería abolirse. La propiedad personal refiere principalmente a bienes muebles, pero a veces incluye a la vivienda y a otros bienes de uso o de consumo personal. Incluiría también a las cosas que tienen un valor especial para nosotros, y podríamos pensar incluso en incorporar en esta categoría a &lt;a href=&quot;https://filosofiadelfuturo.com/expandiendo-nuestra-mente/&quot;&gt;todo aquello que constituya parte de nuestra identidad personal&lt;/a&gt;. La propiedad privada a la que se opone el marxismo no es esa, sino la de los medios de producción o de las grandes extensiones de tierra que incrementan la desigualdad entre las personas, y respecto de la cual el beneficio público de su socialización sería sumamente significativo.&lt;/p&gt;

&lt;p&gt;Cuando hablamos de liberar el acceso a ese cuerpo gigantesco de datos, a esa herramienta que generamos colectivamente y que pocos usufructúan, nos llenamos de inquietudes. Esto es porque nuestros datos, en principio, cumplen con los dos aspectos de la propiedad. El conjunto de datos personales cae en la primera categoría, son nuestros, propios, son datos privados y de una intimidad que desearíamos que fuera inviolable. Querríamos poder controlarlos como lo hicimos siempre antes en la historia. Sin embargo, el cuerpo total de los datos sociales, que incluye al conjunto anterior y más pequeño de los datos nuestros, cae en la otra, y probablemente con el tiempo lo haga cada vez de un modo más rotundo.&lt;/p&gt;

&lt;p&gt;Frente a la objeción de que el comunismo aboliría la propiedad personal, Marx y Engels, en su manifiesto, no sólo afirman que no apuntan a hacer tal cosa, sino que además replicaban observando lo siguiente: esa misma propiedad, la de la casa y los objetos, ya la estaban aboliendo los mismos capitalistas en el siglo XIX. La observación, que ya no aplica del todo a esa clase de bienes, sí aplica de algún modo a nuestros datos. Aunque sea cierto que conservamos nuestra privacidad respecto de muchas personas, ésta no existe para los centros de poder. Tienen, además, el poder de destruirla para todo el resto en cualquier momento. Es sorprendente, pero nunca tuve con nadie una relación de tanta intimidad como con facebook (aunque bastante unilateral, por cierto).&lt;/p&gt;

&lt;p&gt;Existen, por supuesto, soluciones a estas inquietudes que permitirían socializar los aspectos productivos de los datos a nivel social, sin por eso incurrir en violaciones de la privacidad personal. Una de ellas es &lt;a href=&quot;https://en.wikipedia.org/wiki/Data_anonymization&quot;&gt;anonimizar&lt;/a&gt; los datos de manera tal que para cada individuo virtual sea muy difícil de rastrear su contraparte humana. Existen varios métodos criptográficos que permitirían hacer eso de modo seguro, y así lograr distribuir el potencial de aprendizaje enorme que significa tanta información sin que nos amenace. Implicaría que la base de datos que nos fuera accesible no relacionara cada acción registrada con una persona, sino con algún número o identificador del cual no conocemos su denotación. Por supuesto que algunas acciones deberían ser filtradas para que este método fuera efectivo, como la enorme cantidad de correos electrónicos que envié en que puse mi firma.&lt;/p&gt;

&lt;p&gt;Otra posibilidad, de menos alcance democrático y productivo pero más segura aún, es la socialización de los datos bajo &lt;a href=&quot;https://en.wikipedia.org/wiki/Differential_privacy&quot;&gt;privacidad diferencial&lt;/a&gt;. El concepto, en este caso, es no liberar la base de datos en sí (como individuos virtuales de los cuales no se sabe quiénes son) sino las conclusiones estadísticas o generales que nacen de sus estudios. El uso productivo de los datos nace de sus análisis generales, con lo cual, si se distribuyen los frutos de esos análisis y sólo ellos, el riesgo de violación de la privacidad es mínimo. Este último caso trae otros problemas. ¿Cómo auditar que se distribuyen todos los frutos si el proceso se mantiene en secreto? Pero asumiendo que pudiera garantizarse que el cumplimiento, seguirían reteniendo el poder absoluto de decisión sobre qué aprender, qué mostrar y para qué usar esa herramienta de poder sin precedentes.&lt;/p&gt;

&lt;p&gt;¿Cómo superar esta contradicción entre privacidad y soberanía? ¿Qué estrategia se puede tomar para distribuir esa forma de propiedad privada sin defenestrar nuestra propiedad personal? ¿Cómo están almacenados todos esos datos? ¿Exactamente cuáles son? ¿Cuáles hay que distribuir? ¿Cuáles pueden ser anonimizados como medida suficiente de seguridad? De aquellos entre los que no, ¿quiénes decidirían qué investigar, quiénes investigarían, y quiénes auditarían el proceso si se usara el método de privacidad diferencial? Son discusiones que incorporan aspectos técnicos y ético-políticos, y que llegado el caso, no parecen ser resolubles de un día para otro.&lt;/p&gt;</content><author><name></name></author><category term="datos" /><category term="propiedad" /><category term="coronavirus" /><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/propiedad_datos.jpeg" /><media:content medium="image" url="http://localhost:4000/propiedad_datos.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Vigilancia o libertad: el dilema de la pandemia</title><link href="http://localhost:4000/vigilancia-libertad/" rel="alternate" type="text/html" title="Vigilancia o libertad: el dilema de la pandemia" /><published>2020-04-11T00:00:00+02:00</published><updated>2020-04-11T00:00:00+02:00</updated><id>http://localhost:4000/vigilancia-libertad</id><content type="html" xml:base="http://localhost:4000/vigilancia-libertad/">&lt;p&gt;Actualmente generamos enormes volúmenes de información. Ya sea con la localización de nuestros celulares, con nuestras búsquedas en internet o con los datos biométricos que registran cámaras en la vía pública, alimentamos continuamente bases de datos privadas que recopilan información acerca de nosotros. Esto, en algún sentido, nos convierte en &lt;a href=&quot;https://filosofiadelfuturo.com/somos-informacion/&quot;&gt;seres informacionales&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Todos estos procesos de medición pueden ser sintetizados bajo el término de &lt;em&gt;vigilancia&lt;/em&gt;. Si bien es difícil no otorgarle una connotación peyorativa a este concepto, podemos considerar que se trata de una actividad que, en principio, es neutral con respecto a la ética y a los valores: medir y recopilar información privada no es estrictamente algo malo. En caso de que lo fuera, la discusión sobre si continuarla quedaría resuelta desde su comienzo, no quedando otra respuesta que eliminarla. Pero sus beneficios nos son claros actualmente, en tanto que &lt;a href=&quot;https://filosofiadelfuturo.com/chips-antorchas/&quot;&gt;son una herramienta invaluable para combatir la pandemia que atravesamos&lt;/a&gt;. Sin embargo, permitir estas prácticas nos pone frente a algunos dilemas.&lt;/p&gt;

&lt;h2 id=&quot;los-dilemas-de-la-vigilancia&quot;&gt;Los dilemas de la vigilancia&lt;/h2&gt;

&lt;p&gt;Un derecho básico que todxs deberíamos tener es la libertad, entendida en un sentido muy simple como la posibilidad de disponer de medios para realizar las acciones que deseamos, siempre y cuando éstas no perjudiquen a terceros. Dado que ser libre es un derecho, debería estar entre nuestras posibilidades acceder a las grandes bases de datos de información personal siempre que deseáramos actuar con esta información sin ir en detrimento de libertades ajenas. Esto, de hecho, no sucede. Pero si sucediera, entonces garantizar que ninguna persona hiciera un abuso de su libertad y utilizara esta información de modo perjudicial para terceros sería muy difícil.&lt;/p&gt;

&lt;p&gt;Un ejemplo resonante de esta situación es lo que se vivió con la consultora &lt;em&gt;Cambridge Analytica&lt;/em&gt;. Esta empresa prestó servicios principalmente a campañas políticas en distintos países para identificar votantes indecisxs, y bombardearlos consecuentemente con anuncios sensacionalistas que manipularan su decisión de voto. Si bien es cierto que la manera en que esta consultora accedió a los datos privados de usuarios de Facebook fue ilegítima, dado que no hubo consentimiento alguno por parte de las personas en cuestión para brindar sus datos, de todos modos podría argumentarse que esta empresa era libre de obtener los recursos que les permitieran realizar sus objetivos, bajo la promesa de no atentar contra libertades ajenas. El final de la historia hoy nos es conocido: esta promesa no fue cumplida.&lt;/p&gt;

&lt;p&gt;Un primer paso para aliviar esta dificultad es, sin duda, la educación. Una nueva &lt;a href=&quot;https://filosofiadelfuturo.com/ilustracion-en-la-era-de-la-informacion/&quot;&gt;Ilustración en estos tiempos de información&lt;/a&gt; implicaría poner rápidamente en agenda una instrucción acerca de la dinámica de los datos: cómo estos son recolectados, quiénes los almacenan, y cómo los utilizan. De esta manera, las personas tendrían una mayor posibilidad de involucrarse en debates acerca de su propia privacidad en Internet, o de si realmente nos corresponde ser tan libres como para acceder a datos privados de otra persona.&lt;/p&gt;

&lt;p&gt;Esta instrucción, naturalmente, debería incluir la historia de utilizaciones perjudiciales que se han hecho de la información, como fue el caso de &lt;em&gt;Cambridge Analytica&lt;/em&gt;. A su vez, la libertad nunca ha sido perdida como derecho. Entonces, ¿realmente querríamos que las empresas, los gobiernos, o alguien, tenga nuestra información? La vigilancia y la manipulación, si bien no están conectadas necesariamente, han tenido una historia de íntima cercanía. Y si pretendemos conservar nuestra libertad, haríamos bien en evitar ser manipuladxs. En vistas de esta tradición, toda persona tiene &lt;a href=&quot;https://gdpr-info.eu/art-17-gdpr/&quot;&gt;derecho a ser olvidada&lt;/a&gt;, es decir, podemos solicitar que una empresa elimine toda información que haya recopilados sobre nosotrxs. Esto nos llevaría a que, si consideramos que una instrucción de las personas es necesaria para comenzar a abrir el acceso a las grandes bases de datos de información, entonces esas bases de datos deberían quedar vacías.&lt;/p&gt;

&lt;p&gt;De manera que, si lo que se dijo hasta acá es correcto, la vigilancia es una práctica sumamente problemática. En particular, se vuelve difícil sostener la recopilación de datos privados sin que esto lleve a una violación de la libertad de las personas vigiladas, y la educación como medida de aliviamiento podría llevar al vaciamiento de los &lt;em&gt;datacenters&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;la-vigilancia-en-tiempos-del-coronavirus&quot;&gt;La vigilancia en tiempos del coronavirus&lt;/h2&gt;

&lt;p&gt;La tensión en que estos dilemas nos ponen es particularmente acuciante cuando nos encontramos en un momento como el que atravesamos actualmente, con la pandemia del coronavirus. Mientras que por un lado es fundamental desplegar un operativo de control y seguimiento para tener información acerca del estado de las personas contagiadas, esto nos lleva precisamente a los problemas que consideramos.&lt;/p&gt;

&lt;p&gt;La efectividad de la vigilancia como método preventivo tiene claros ejemplos en Oriente. En Corea del Sur, por ejemplo, la cantidad de contagiadxs fue regulada con mucho éxito, como también el porcentaje de personas que fallecen a causa de la enfermedad. Se trata de un país con experiencia en el manejo de epidemias, ya que en 2015 vivieron una situación de este tipo con el brote del MERS-CoV. Pero una estrategia de abundantes tests sobre la población más &lt;a href=&quot;https://docs.google.com/presentation/d/1jQ4NZCJbcZEuabRE709exxas37fgTy3WmoAvW6LsOkw/edit#slide=id.g81a94103b3_4_0&quot;&gt;plataformas digitales de seguimiento y control&lt;/a&gt; le permitieron al país controlar la difusión de la enfermedad incluso teniendo varios casos confirmados. También es notable el caso de China. Si bien se ha señalado que el país &lt;a href=&quot;https://www.bloomberg.com/news/articles/2020-04-01/china-concealed-extent-of-virus-outbreak-u-s-intelligence-says&quot;&gt;ha escondido las cifras reales&lt;/a&gt;, lo que vuelve dudosos los reportes de su situación, no se puede dejar de reconocer el operativo que montaron. Entre &lt;a href=&quot;https://www.comparitech.com/vpn-privacy/the-worlds-most-surveilled-cities/&quot;&gt;las primeras 10 ciudades más vigiladas del mundo&lt;/a&gt; con cámaras CCTV, sólo dos de ellas no se encuentran en China. Esto permite a las autoridades del país monitorear en todo momento las puertas de las casas de personas contagiadas para asegurarse de que no salgan.&lt;/p&gt;

&lt;p&gt;En &lt;a href=&quot;https://www.cnbc.com/2020/03/27/coronavirus-surveillance-used-by-governments-to-fight-pandemic-privacy-concerns.html&quot;&gt;un artículo reciente&lt;/a&gt; hay referencias a las medidas tomadas por otros países de la región, todas orientadas al desarrollo de aplicaciones o utilización de tecnologías previamente existentes (como sistemas de geolocalización en teléfonos celulares) con el mismo fin. Además, &lt;a href=&quot;https://www.xataka.com/servicios/apple-google-se-alian-frente-al-covid-19-e-integraran-sistema-seguimiento-contagios-basado-bluetooth-ios-android&quot;&gt;Apple y Google anunciaron un sistema para sus propios dispositivos&lt;/a&gt; por medio del cual se registran códigos encriptados de identificación de los dispositivos móviles con los que se haya tenido una cercanía considerable. Con esto, Occidente se suma al operativo de vigilancia tecnológica de lxs ciudadanxs.&lt;/p&gt;

&lt;p&gt;Una conclusión inquietante que se extrae de estos fenómenos es que la velocidad con la que estos operativos fueron montados sería realmente extraordinaria si no fuera que se trataba de una red de control que existía con anterioridad. Pero no hay dudas de que estas tecnologías existían entre nosotrxs antes de la pandemia. Esto fue blanqueado en Israel, donde la tecnología que se utiliza formaba parte de un dispositivo para la lucha contra el terrorismo. Pero la otra consecuencia, aún más inquietante, es que esta situación es propicia para consentir un mayor nivel de vigilancia que el que previamente se consideraba “aceptable”. Dado que es sumamente importante que este tipo de tecnologías existan (sus beneficios son visibles), es importante que brindemos nuestros datos para favorecer el accionar de los gobiernos. Pero cuando esto termine, no debemos olvidar que estos datos nos pertenecen, y que es nuestro derecho luchar para que los gobiernos o las empresas aprovechen nuestra vulnerabilidad para violar lo que nos corresponde&lt;/p&gt;

&lt;p&gt;En pocas palabras, de lo que se trata es de conservar nuestra libertad. Qué tan libres seamos es inversamente proporcional a qué tan vigiladxs seamxs. Negar la vigilancia previa a la pandemia sería ingenuo: más allá de las denuncias de Edward Snowden sobre el espionaje masivo por parte del gobierno de Estados Unidos, nunca quedamos exentxs del mecanismo de control. Negarse a brindar datos para combatir el coronavirus sería necio: estas herramientas podrían salvarnos. El problema es qué pasará después.&lt;/p&gt;</content><author><name></name></author><category term="datos" /><category term="redes" /><category term="coronavirus" /><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/vigilancia_libertad.jpeg" /><media:content medium="image" url="http://localhost:4000/vigilancia_libertad.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Chips y Antorchas: El enemigo invisible y cómo verlo</title><link href="http://localhost:4000/chips-antorchas/" rel="alternate" type="text/html" title="Chips y Antorchas: El enemigo invisible y cómo verlo" /><published>2020-04-04T00:00:00+02:00</published><updated>2020-04-04T00:00:00+02:00</updated><id>http://localhost:4000/chips-antorchas</id><content type="html" xml:base="http://localhost:4000/chips-antorchas/">&lt;p&gt;El virus arrasa, la cuarentena también. Parece haber un dilema muy difícil de enfrentar. Cuando del otro lado el enemigo es invisible, las opciones que nos quedan son muy pocas. Si no sabemos quiénes están infectados, la única forma segura de detener el avance de la pandemia es asumiendo que cualquiera podría estarlo. Se sigue, entonces, que debemos o bien reducir nuestro contacto con todo el mundo y quedarnos en casa (con los costos económicos y de calidad de vida que eso implica), o bien decidir que asumir ese costo es una estrategia inviable, que la solución nunca debería ser peor que el problema, recomendar barbijo y algún grado de distanciamiento y a otra cosa. Parece que a los países que eligieron la segunda opción les está saliendo el tiro por la culata. Entre los que elegimos la primera, sin embargo, rondan las incertidumbres respecto del futuro. ¿Hasta cuándo puede sostenerse la cuarentena total? ¿Cuánto más va a durar la pandemia? ¿Cómo seguir desde acá? ¿Qué hacer después?&lt;/p&gt;

&lt;p&gt;Lo interesante de nuestros tiempos (y de cualquier cambio rotundo entre dos épocas) es que muchos métodos de tiempos anteriores pueden sostenerse hasta que alguna crisis prueba su obsolescencia. Frente a un virus contagioso aún asintomático y una imposibilidad práctica de distribuir tests diagnósticos masivamente, las salidas todo o nada del dilema taza-taza o laissez faire agotan las opciones desde tiempos inmemoriales. El asunto es que hoy sabemos que no es que el virus sea invisible: estamos a oscuras y nunca prendimos la linterna.&lt;/p&gt;

&lt;p&gt;¿Dónde nos encontramos ahora? No queremos la masacre que significa la pandemia ni podemos sostener la cuarentena indefinidamente. Por ahora, podemos hacer pocos tests y eso nos pone en desventaja. Sin embargo, por alguna razón, la mayoría de las personas que habitamos este país caminamos con un rastreador en el bolsillo, nuestro celular, que documenta cada uno de nuestros movimientos. Esto genera una infinidad de datos que se registran cada segundo, se transmiten directamente a servidores privados y, como cierta vez tildamos una cajita que figuraba al lado de un “acepto”, alguna frase en letra chica determina que esos datos son de propiedad ajena. Los movimientos de la sociedad argentina, con quién se cruza cada quién, el lugar en que vivimos y el lugar en que compramos, nuestros patrones, nuestras regularidades y nuestro historial, la densidad de gente en cada lugar y en cada momento, todo ese mapa, completo, existe y no nos pertenece.&lt;/p&gt;

&lt;p&gt;Ese mapa es la linterna que permite escapar al dilema que enfrentábamos en siglos anteriores. Toda esa información, sumada a la que pueden darnos los pocos tests que hoy en día podemos llevar a cabo, puede salvarnos tanto del contagio masivo, del colapso sanitario y de las miles de muertes, como del constante “yendo de la cama al living”, de la bancarrota general y del colapso económico. Es información que generó el conjunto de nuestra sociedad y que nos es inaccesible.&lt;/p&gt;

&lt;p&gt;Cuando se tiene el mapa de los movimientos de la gente, el virus ya no es invisible. A partir de los casos confirmados de COVID19 y de sus movimientos, se puede inferir la probabilidad que tiene cada quién de haberse contagiado. Ese mapa permite usar los pocos tests que podemos llevar a cabo de un modo mucho más eficiente, de manera que maximicen la información que cada test nos brinda sobre el sistema. Permite también establecer la cuarentena de un modo selectivo y flexible para que, aún evitando el avance de la epidemia, no implique un costo económico casi tan terrible como ella. Nos permite saber con alto grado de fidelidad en dónde puede estar el virus y obrar al respecto en modo ágil y efectivo. ¿Cuántos miles de vidas se cobraría la pandemia si no hacemos nada? ¿Cuánto se disparan la pobreza, la desigualdad y el malestar social si la cuarentena total continúa? Si bien las salidas del dilema son ambas desastrosas, existe una tercera vía que rápidamente nos permitiría hacer las cosas del mejor modo posible. Está toda la red, ya preparada, de relevamiento de información, de almacenamiento y de procesamiento. Podríamos salvarnos con apenas el poder de acceder, desde el estado, a esa información. Pero bueno, un botoncito de “I agree” dicta que su derecho al monopolio del uso de nuestros datos es inviolable, así que tenemos que elegir entre morirnos de coronavirus o de hambre.&lt;/p&gt;

&lt;p&gt;A veces, cuando en tiempos de sequía algún aristócrata acaparaba los granos, la mayoría campesina se olvidaba de sus viejos juramentos de lealtad. Si habían labrado, sembrado y cosechado, ¿también por eso habrían debido desnutrirse? Por suerte para Google, las relaciones de propiedad y sus efectos son mucho más opacas en la infósfera. ¿Cuál es el enemigo invisible?&lt;/p&gt;</content><author><name></name></author><category term="datos" /><category term="redes" /><category term="coronavirus" /><summary type="html">El rol de los datos en los tiempos de la pandemia del coronavirus</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/chips_antorchas.jpg" /><media:content medium="image" url="http://localhost:4000/chips_antorchas.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Pandemia de ideas</title><link href="http://localhost:4000/pandemia-ideas/" rel="alternate" type="text/html" title="Pandemia de ideas" /><published>2020-03-22T00:00:00+01:00</published><updated>2020-03-22T00:00:00+01:00</updated><id>http://localhost:4000/pandemia-ideas</id><content type="html" xml:base="http://localhost:4000/pandemia-ideas/">&lt;p&gt;¿Qué tienen en común la primavera árabe, una noticia falsa en internet y el virus que nos obliga a guardarnos en casa estas próximas semanas? Cuando existen fenómenos que desde algún punto de vista son similares, los modelos formulados para entender la evolución de cualquiera de ellos sirve para entender al resto. Por otra parte, entender un fenómeno nos permite obrar e intervenir sobre el mismo, o en otras palabras, hacer ingeniería. Un modelo habilita métodos, y cuando múltiples fenómenos son similares, métodos similares pueden ser aplicados para intervenir en todos ellos.&lt;/p&gt;

&lt;p&gt;Para acercarnos un poco a estos conceptos, imaginemos que queremos construir un modelo de la transmisión del VIH en una población para poder luchar contra su avance. Empezamos poniendo una hoja de papel sobre el escritorio, como suele hacerse, porque queremos establecer algunos garabatos preliminares. Lo primero que vamos a hacer es un pequeño mapa de la población de la cual estamos hablando, que consistirá solamente en dibujar un punto por cada persona. De esta manera, cada persona está representada unívocamente por un punto, y cada punto refiere a una persona en particular. Habiendo hecho esto, nos enfrentamos con el segundo paso, que es fundamental para terminar nuestro mapa. Vamos a dibujar también ciertas líneas, conectando pares de puntos, que van a representar algo así como “puentes” a través de los cuales el virus puede pasar de una persona a otra. Para esto, por suerte, hicimos una encuesta relativamente completa, que nos permite dibujar varios segmentos entre pares de puntos (personas) que mantienen intercambio sexual o sanguíneo. En los casos en los cuales no contamos con la información precisa, estimamos también el dibujo de algunas líneas que podemos inferir a partir de nuestra encuesta, de alguna cosa que leímos de psicología social y del llamado a especialistas en sociología que se habían ofrecido a ayudarnos.&lt;/p&gt;

&lt;p&gt;Tenemos ahora, frente a nosotros, un grafo, es decir, un conjunto de puntos de los cuales algunos pares de ellos están conectados por líneas. El grafo es el modelo usado para representar no solamente grupos de personas e interacciones sexuales, sino cualquier conjunto de entidades de las cuales nos interesan ciertas conexiones. A simple vista, vamos a poder observar que algunos de esos puntos tienen muchas líneas que los conectan, mientras que algunos otros tienen pocas o ninguna (nodos de alta o baja valencia). Además, vamos a poder observar propiedades generales de la red. Por ejemplo, si en el dibujo se pueden distinguir grupos de puntos entre los cuales solamente existan dos o tres puentes, o si hay subgrupos en los cuales todos están conectados con todos (cliques), o por ejemplo, cuál es la distancia promedio entre dos puntos en la red (la distancia se mide como la cantidad de “líneas” que hay en un camino mínimo de un punto a otro).&lt;/p&gt;

&lt;p&gt;Lo último que falta distinguir es el conjunto de puntos portantes del virus y la probabilidad de contagio que se da, de uno a otro, en cada uno de los puentes. Lo que hicimos hasta acá ya lo podemos meter en una computadora (habiendo estudiado algo de computación sobre grafos, o mandándole un mensaje a alguien que sepa del tema), y observar, paso por paso, una predicción de cómo el virus va a evolucionar a través del tiempo. Además, tenemos la posibilidad de “jugar” con el modelo para mejorar nuestra comprensión del mismo. Aprovechando que está todo programado, podemos correr el modelo varias veces en la computadora, con distintas variaciones respecto de qué puntos o líneas imaginamos poder eliminar, o sustituir, o generar, y a partir de eso seguir aprendiendo muchas cosas, desde conclusiones muy generales de qué puntos atacar en una red genérica hasta conclusiones muy particulares de la red específica que tenemos en nuestras manos.&lt;/p&gt;

&lt;p&gt;Pero no termina ahí. A partir de este modelo, ahora, podemos encontrar grupos de personas específicos sobre los cuales los efectos de la concientización en materia de profilaxis sean mejores para la red. En otras palabras, podemos encontrar formas de a bajo costo, reduciendo al máximo el número de personas afectadas por una campaña de emergencia de educación sexual, se minimice el número de personas afectadas por el virus. Por ejemplo, a partir de nuestro mapa, podemos encontrar las personas “puente”, que son las pocas personas que permiten el paso entre distintos grupos muy densamente conectados en su interior. Podemos, además, concientizar a las personas “autopistas”, que son las personas que conectan puntos que de no existir ellas estarían muy lejos, para ralentizar la propagación del virus. Podemos, a partir de nuestro modelo basado en redes, sacar muchas conclusiones muy útiles para detener el avance del virus.&lt;/p&gt;

&lt;p&gt;Supongamos que ahora nos volvemos malvados, cegados por el nuevo poder que hemos adquirido, y queremos usar esta herramienta para el mal. El mapa y el modelo ya los tenemos, y haciendo nuevos experimentos, podemos también localizar grupos mínimos de personas iniciales que asegurarían una propagación máxima del virus. Entonces, si queremos afectar a muchas personas de nuestra población, ya tenemos claro a quiénes contagiar primero.&lt;/p&gt;

&lt;p&gt;La construcción de esta clase de modelos que cuentan con i) un grafo, ii) un subconjunto distinguido de los puntos del grafo que serían los “portantes” de algo, y iii) un estimativo de la probabilidad de transmisión sobre cada una de las líneas nació así, para combatir epidemias, y por supuesto fue muy efectiva. Pero es útil también en otros campos, por un motivo que responde a la pregunta inicial del texto: en un sentido abstracto, los tres fenómenos mencionados funcionan a partir del mismo mecanismo. Existe un grupo de personas, algo que puede transmitirse de persona a persona (en los dos primeros casos una idea, en el tercero una partícula de proteínas y ARN), y una serie de “nexos” o “puentes” que muestran que existe una cierta probabilidad de contagio entre pares de personas de nuestra población. El concepto clave es el de evolución respecto de una red.&lt;/p&gt;

&lt;p&gt;Los modelos epidemiológicos son hoy en día, y precisamente por la similitud en el funcionamiento de estos distintos fenómenos, utilizados para manipular la transmisión de información en redes. Para unas pocas empresas, dueñas de las distintas redes sociales digitales que usamos como canal principal de comunicación, los puntos y las líneas (que, seamos realistas, son muchos e imposibles de dibujar) no tienen que ser dibujados, porque ya los tienen en sus bases de datos. Entre las publicaciones académicas de los últimos años, se encuentran varios papers dedicados al “rumor blocking problem”, que es esencialmente hacer lo mismo que hicimos recién para el VIH pero aplicado a “rumores” (o cualquier idea, desde voltear un gobierno autoritario hasta las ideas disparatadas que algunas personas comparten por Whatsapp) en que se presentan formas muy efectivas en términos computacionales de encontrar los puntos clave para detener la expansión de una idea, tratando el problema abierta y explícitamente desde los métodos epidemiológicos. Existen tantos otros papers dedicados a “influence maximization”, que desde los mismos principios metodológicos explican cómo hacer, también con ideas en una red social, lo que hicimos cuando atravesamos nuestro período malvado al estudiar el VIH. Cuando en la conferencia de prensa en que se anunció el DNU para la cuarentena obligatoria el presidente proclamó “tenemos que enfrentar dos cosas: a la pandemia y a la psicosis”, podría también haber dicho que las dos cosas pueden enfrentarse de la misma manera. Los casos de psicosis colectiva también se estudian desde los mismos modelos y están sujetos a los mismos métodos que las epidemias y la distribución de memes.&lt;/p&gt;

&lt;p&gt;La disciplina que estudia estos fenómenos y produce métodos de aplicación (de ingeniería sobre enfermedades, ideas y sociedades) es la llamada “computación social”. Uno de sus resultados empíricos es una observación de cómo funcionamos que descubrieron codo a codo con la psicología social, muestra que hacemos mucho más caso a la red y a la comunicación con pares que a los clásicos medios masivos de comunicación. Pero hoy en día, (y más aún en los años que se vienen) la horizontalidad y anarquía democrática que disfrutábamos en las redes de internet sufrirá una transición hacia la moderación, manipulación y capacidad de tutela de nuestras voces. La potencialidad de viralización de una idea en las redes sociales digitales que permitió voltear a Gadafi y Mubarak y que fomentó la explosión del feminismo de tercera y cuarta ola se restringe cuando existen métodos epidemiológicos que permiten, con muchísima efectividad, aplacar la expansión del “virus”. El problema se vuelve grave cuando la capacidad de aplicación de dichos métodos pertenece únicamente a un oligopolio informático que acapara en sus bases de datos toda la información de la red, que vos y yo no tenemos, y acapara en sus procesadores la capacidad de cómputo para ejecutar los algoritmos necesarios, que en la mía y en la tuya tardarían un tiempo prohibitivo. Esta asimetría, de tendencia creciente, es peligrosísima para la libertad de expresión y para cualquiera de esas cosas que concibamos como democracia.&lt;/p&gt;

&lt;p&gt;A no desesperar. Ciertas veces, por acción tardía, por contagiosidad o por quién sabe qué factores, estos métodos epidemiológicos no pueden prevenir la pandemia. Hoy vivimos eso con un virus. ¿Armamos una idea?&lt;/p&gt;</content><author><name></name></author><category term="fake news" /><category term="información" /><category term="red" /><summary type="html">Los movimientos sociales, las noticias falsas y los virus no son tan distintos</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/pandemia_ideas.jpg" /><media:content medium="image" url="http://localhost:4000/pandemia_ideas.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Nuestras mentes están hechas de transistores y amistades</title><link href="http://localhost:4000/mentes-transistores-amistades/" rel="alternate" type="text/html" title="Nuestras mentes están hechas de transistores y amistades" /><published>2020-03-07T00:00:00+01:00</published><updated>2020-03-07T00:00:00+01:00</updated><id>http://localhost:4000/mentes-transistores-amistades</id><content type="html" xml:base="http://localhost:4000/mentes-transistores-amistades/">&lt;p&gt;Hace unos días me robaron mi mochila con la computadora adentro. Qué cagada.&lt;/p&gt;

&lt;p&gt;¨No, qué bajón. Perdiste cosas importantes?¨&lt;/p&gt;

&lt;p&gt;¨No, medio que tengo todo entre Drive y Git. Lo que no está subido casi que ni lo uso. Películas y cosas así perdí nada más. Algunos PDFs…¨&lt;/p&gt;

&lt;p&gt;?Por qué me afectó tanto estar dos semanas sin la computadora? Ni siquiera sin computadora. Esto lo estoy escribiendo en la Mac de mi hermana, que me la está compartiendo un poco hasta que consiga reemplazarla. ¨Es una herramienta de trabajo¨, me repito.&lt;/p&gt;

&lt;p&gt;Qué buena la sensación de entrar, aunque sea de una computadora ajena, a mi cuenta de Google y que siga todo como  de costumbre. Mis documentos, mis artículos guardados para leer. Cuando empiezo a tipear en el buscador, se me completa con las mismas páginas de siempre. No es de particular ayuda, pero se siente familiar.&lt;/p&gt;

&lt;p&gt;El timing, invariablemente, es pésimo. Días antes de rendir un parcial en la facultad para el que tengo que &lt;em&gt;programar&lt;/em&gt;. Pero es más que eso, me gusta llevarla de un lado a otro. Siento que me puedo poner a trabajar en cualquier lado, en cualquier cosa. Escribir, estudiar, leer.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;The Extended Mind&lt;/em&gt; (mente extendida) es el segundo paper de filosofía más citado de la historia. Es medio trampa, porque Hegel y Kant y todos esos escribían Libros, no papers para journals filosóficos, pero bueno. Para mí vale igual.&lt;/p&gt;

&lt;p&gt;A los estándares de hoy, Andy Clark no patea la pelota demasiado lejos del área de lo razonable en su famoso paper: la mente hace un montón de cosas (conscientes o no); si esas actividades las hace algun circuito neuronal adentro de nuestro cráneo, no dudamos en llamarlo una ¨actividad mental¨; si esa misma función se realizara fuera de nuestro cuerpo, también deberíamos considerarla una actividad mental.&lt;/p&gt;

&lt;p&gt;Una crítica que me encantó sobre ese paper decía “Cuando lo publicaron, en el 98’, no era verdad. Hoy sí.”&lt;/p&gt;

&lt;p&gt;-!Bien, encontré las comillas! voy a dejar de poner diéresis-.&lt;/p&gt;

&lt;p&gt;Si la filosofía fuese un deporte, nuestras intuiciones serían la pelota. Argumentos como el de antes son típicos. Pero más típico aún es escuchar historias, narradas específicamente para estirar nuestras intuiciones en alguna dirección en específico.&lt;/p&gt;

&lt;p&gt;Bien sabemos, y bien sabía Andy Clark, que un argumento no es una buena forma de convencer a nadie. Escrito en tres oraciones o expresada con todo el rigor de la filosofía profesional, la idea la logra ilustrar con una pequeña historia (la traslado a Buenos Aires):&lt;/p&gt;

&lt;p&gt;Inga es una estudiante de letras en Puan que sus amigxs le contaron sobre una exposición del MALBA a la que planeaban ir ese sábado. A Inga le pareció interesante y les dijo que lxs veía ahí.&lt;/p&gt;

&lt;p&gt;Otto es mayor a Igna y ya está Jubilado. Otto tiene Alzheimer y, como haría mucha gente que tiene esa enfermedad, anota en su libreta que hay una exposición el sábado en el MALBA a la que le interesa ir.&lt;/p&gt;

&lt;p&gt;Llega el sábado e Inga se da una ducha cuando se despierta, a las 12pm. Mientras se baña se acuerda que había quedado en ir al MALBA y que para tomar el 130 tiene que caminar un poco, pero es lo más rápido.&lt;/p&gt;

&lt;p&gt;Otto se despierta temprano y lee su cuaderno como todas las mañanas. Sin él, no sólo no podría recordar que el MALBA está en Figueroa Alcorta, si no que tampoco sabría que hay una exposición. Ni siquiera recordaría que le interesaría ir.&lt;/p&gt;

&lt;p&gt;No sé si moraleja es la palabra, pero este cuentito analógico es el ejemplo clásico de mente extendida: un objeto del lado equivocado del cráneo que sigue cumpliendo con funciones que, en un caso análogo, consideramos mentales.&lt;/p&gt;

&lt;p&gt;Lo bueno del paper (y lo malo de ese ejemplo) es que no sólo aplica a muletas cognitivas para casos donde hubo daño, si no que nos aplica a todos a través de muchísimos tipos de tecnologías. Sí, Otto usa una libreta porque no puede recordar por su cuenta. Pero hace muchísimo tiempo que usamos libretas para recordar eventos o que usamos papel para llevar cuentas o mantener mapas. Hacemos eso no porque estemos dañados, si no porque aprovechamos otros medios que son mejores para ciertas tareas. Sí, antes de Google recordábamos más cosas. Pero nuestra especie evolucionó para hacer uso de nuestro entorno.&lt;/p&gt;

&lt;p&gt;De la misma forma en la que dominar el fuego nos permitió hacer casi toda la digestión fuera de nuestro cuerpo (otros animales comen exclusivamente carne cruda y necesitan reposar muchísimo tiempo después de comer), así liberando un poco de energía para usar en cosas más importantes, también dominar la escritura nos permitió hacer cosas que antes no teníamos chance.&lt;/p&gt;

&lt;p&gt;Como puntada final, una vez que ya compraste que no es ridículo pensar a la agenda de Otto como parte de su mente, Andy dice que la mente extendida no son sólo objetos materiales o tecnológicos. Si Inga no se acordaba de ir al MALBA, cabe pensar que el rol de su memoria lo hubiese tomado una amiga que le manda un Whatsapp. No es el teléfono en este caso lo único fuera del cráneo que actúa como mente, si no también la amiga. La amiga y la agenda de la amiga, si ella fuera más ordenada que Inga.&lt;/p&gt;

&lt;p&gt;Yo estuve sin computadora estas dos semanas. No fue un acto voluntario. Me inhibió de trabajar, de escribir y de estudiar. Claramente, es más fácil recuperarse de un disco rígido faltante que de una parte de la corteza prefrontal. Pero - a mí me convence -, perder acceso a cuadernos o diarios no es tan distinto a perder recuerdos. En particular, quedarse sin Google Calendar o sin Whatsapp no es tan distinto a que Otto pierda su agenda o a que a Inga la deje de llamar su amiga.&lt;/p&gt;

&lt;p&gt;Por suerte, no perdí mucho más que algunos PDFs. La mayoría de mis procesos mentales pasan o en mi cerebro o en Google Drive. Espero que no les pase nada malo a ninguno de los dos.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;A continuación, dejamos algunos links para continuar la lectura:&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://futurephilosophy.github.io/expandiendo-nuestra-mente/&quot;&gt;Extendiendo nuestra mente&lt;/a&gt;, Filosofía del Futuro&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://www.newyorker.com/magazine/2018/04/02/the-mind-expanding-ideas-of-andy-clark&quot;&gt;The Mind-Expanding Ideas of Andy Clark&lt;/a&gt;, New Yorker&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="mente extendida" /><summary type="html">El pensamiento también vive fuera de la cabeza</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/mentes_transistores_amistades.png" /><media:content medium="image" url="http://localhost:4000/mentes_transistores_amistades.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Delitos proxy</title><link href="http://localhost:4000/delitos-proxy/" rel="alternate" type="text/html" title="Delitos proxy" /><published>2020-02-22T00:00:00+01:00</published><updated>2020-02-22T00:00:00+01:00</updated><id>http://localhost:4000/delitos-proxy</id><content type="html" xml:base="http://localhost:4000/delitos-proxy/">&lt;p&gt;Se usa el término “proxy” para referirse a fenómenos que sustituyen a otros en el cumplimiento de alguna función. Por ejemplo, suele hablarse de “guerras proxy” para referirse a las guerras subsidiarias entre los Estados Unidos y la Unión Soviética durante la guerra fría. No se enfrentaban, en ellas, yanquis y rusos directamente, sino que lo hacían apoyando bandos opuestos en conflictos bélicos en que estuvieran en juego sus esferas de influencia. Las guerras en Corea, Vietnam y Afganistán fueron fenómenos sustitutos, que cumplían la función de enfrentar el capitalismo norteamericano al socialismo soviético, en algo así como una tercerización de la guerra. En informática, se habla de servidores proxy para referirse a los dispositivos que representan clientes en la petición de recursos. En lugar de que el cliente le pida el recurso directamente al servidor, se lo pide al proxy, que hace de intermediario, y se vuelve el sustituto que cumple con la función del cliente.&lt;/p&gt;

&lt;p&gt;No son pocas las veces en que un fenómeno se usa para cumplir las intenciones u objetivos de otro, cumpliendo el papel de sustituto. En el ámbito legal, tenemos el ejemplo del famoso gángster Al Capone, la estrella de la mafia de Chicago, que lo mandaron a Alcatraz después de meterlo en cana por evasión de impuestos. Claro, no encontraban pruebas suficientes para ligarlo con el volumen de muertes y de contrabando por el cual querían juzgarlo, pero sí para encarcelarlo por evasión fiscal. En este caso, la evasión fiscal fue el delito proxy, que sustituía, para el estado de Chicago y los enemigos del Hampa, a los juicios por actividades mafiosas faltas de evidencia. Además de sustituir actividades delictivas para las cuales se carece de evidencia conclusiva, el delito proxy puede ser un proxy de cualquier asunto por el cual pretenda juzgarse a una persona. Hace unos años, en el juicio político a Dilma Rousseff, diversos miembros del senado que votaron su destitución admitían abiertamente que el asunto en juego no era realmente si había habido o no corrupción en Petrobras, sino cómo estaba funcionando la macroeconomía. La corrupción, dicho sea de paso, es un delito proxy paradigmático en nuestro continente que fue utilizado varias veces como sustituto de otros motivos de persecución, relacionados a intereses políticos o distribuciones de poder.&lt;/p&gt;

&lt;p&gt;¿Por qué es tan importante ahora el delito proxy? Por dos motivos. En primer lugar, estamos viviendo hoy en día el auge de un oligopolio de empresas dedicadas a las comunicaciones, con potestad (potestad que solamente tienen ellas) de tener acceso a la mensajería y la actividad en línea de una gran porción de la población. En segundo lugar, un hecho, que es que muchísima gente, a lo largo de su vida, cometió algún delito menor que pasó bajo el radar de la ley de su país, pero que es información accesible para este grupo de empresas. La conjunción de estos dos fenómenos vuelve al delito proxy una institución que permitiría, si estas tendencias continúan, dar de facto a ciertos grupos reducidos y que nadie votó, el poder de usar el poder coercitivo y penal del estado, arbitrariamente, sobre una amplia porción de la población.&lt;/p&gt;

&lt;p&gt;¿Querés meter preso a alguien porque sabés que es malvado? ¿Hay un candidato político que va en contra de tu agenda? ¿Tu vecino te miró mal? Si formás parte de este oligopolio, muy probablemente tenés el poder de, con mecanismos perfectamente legales y sin necesidad de mentir, confabular o romper alguna regla, juzgarlo y ponerlo tras las rejas. Basta usar como proxy alguno de esos delitos menores que nunca había sido juzgado y presentar la evidencia ante la justicia mediante los canales apropiados. Listo, sos un ciudadano correcto y honesto con un poder que pone en jaque al mismísimo estado de derecho. ¿O en realidad no? Si al final el delito proxy fue efectivamente cometido, parece que entonces  el estado de derecho se sigue respetando. Evidentemente ahí hay una pregunta interesante.&lt;/p&gt;

&lt;p&gt;Si es tan legal el método de juzgar mediante un proxy, y al final sí cometiste ese delito que funciona de proxy ¿qué importa cuáles eran las intenciones por detrás? Pero si salieran a la luz todos esos delitos menores de todo el mundo, ¿se los juzgaría a todos? ¿o hay algo en la escasez que garantiza llevar el juicio a término? Al ser privativa la información, es decir, que hay muchísima información que sólo es accesible a un grupo en particular, en el contexto de un sistema que venía castigando un bajo porcentaje de los delitos menores, la decisión de castigar o no, en la práctica, pasa a depender en muchos casos de estos nuevos panópticos. ¿estamos, entonces, ante una situación legal injusta? ¿si fuera así y quisiéramos evitarlo, deberíamos cambiar el sistema legal y penal? ¿o sería, en su lugar, un problema principalmente de asimetría económica?&lt;/p&gt;

&lt;hr /&gt;</content><author><name></name></author><category term="big data" /><summary type="html">Cómo el Big Data puede torcer la ley</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/delitos_proxy.jpg" /><media:content medium="image" url="http://localhost:4000/delitos_proxy.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Inteligencia artificial: la escuela conexionista</title><link href="http://localhost:4000/ia-escuela-conexionista/" rel="alternate" type="text/html" title="Inteligencia artificial: la escuela conexionista" /><published>2020-02-08T00:00:00+01:00</published><updated>2020-02-08T00:00:00+01:00</updated><id>http://localhost:4000/ia-escuela-conexionista</id><content type="html" xml:base="http://localhost:4000/ia-escuela-conexionista/">&lt;p&gt;Estamos viviendo en un momento importante en la historia inteligencia artificial. No son pocos los expertos en el área que afirman que desde hace unos años estamos presenciando un nuevo boom. La década anterior nos mantuvo en una constante alza de nuevos desarrollos, aplicaciones y perfeccionamientos de técnicas computacionales preexistentes que hacen realidad algunas prácticas que antes eran soñadas y, aunque es común que nuestra capacidad de asombro se vaya difuminando a medida que estas tecnologías ingresan en nuestras vidas cotidianas o en los portales de noticias que consumimos, solo basta con detenernos un momento y observar: el reconocimiento de audio y lenguaje natural nos permiten tener diálogos con bots que, por instantes, pueden darnos una ligera sensación de retórica humana. La implementación algorítmica del deep learning, sumado al acceso de enormes bases de datos, habilita a grandes corporaciones a tener la capacidad de cómputo para analizar y predecir comportamientos masivos. Los algoritmos de reconocimiento facial nos ponen al filo de prácticas de poder que pueden hacer tambalear algunos de los preceptos más básicos de la idea de privacidad y anonimato tal como la conocemos. La posibilidad de realizar diagnósticos médicos complejos o de diseñar de drogas de modo automático, nos obligan a redefinir a la medicina. Estos son sólo algunos de los ejemplos que se nos pueden ocurrir. Todas estas aplicaciones de Inteligencia Artificial tienen un denominador común: la aplicación de redes neuronales artificiales, comprendidas dentro del paradigma conexionista.&lt;/p&gt;

&lt;p&gt;Para comprender un poco de qué va esta idea, debemos remontarnos una vez al origen de esta disciplina y visitar a un personaje fundamental para el siglo XX: Alan Turing. Ente sus valiosos aportes se encuentra la delimitación de aquellas funciones que puede procesar una computadora en lo que se dió a conocer como la tesis Turing-Church. De allí, hubo sólo unos pocos pasos para instalar la noción de que la forma de cognición humana era computacional y, por tanto, una computadora podría imitarla. Para esta época, ya se había establecido como un estándar en la neurofisiología que el cerebro está compuesto por unidades llamadas neuronas tal como había descrito Ramón y Cajal en la última década del siglo XIX, y que éstas interactúan entre sí mediante mecanismos de señalización eléctricos explicados en el modelo de Sherrington. Teniendo en cuenta todo esto, los científicos McCulloch y Pitts elaboraron en 1943 uno de los principios para modelar algunas de las funcionalidades abstractas de una neurona. Muy resumidamente, la idea consistía en entender a estas últimas como unidades lógicas que emiten un output una vez que la suma de ciertos inputs supera un valor determinado. Mas de diez años después, Frank Rosenblatt diseñó una implementación computacional llamada Perceptron que, dándole una vuelta de tuerca a la función McCulloch-Pitts, compuso un conjunto de unidades lógicas enlazadas en una red, que permitían representar algunos aspectos de la capacidad de aprendizaje. Esto se hacía a partir de la asignación arbitraria de valores numéricos a cada neurona para posteriormente hacer que realicen predicciones. En función del acierto o desacierto de estas predicciones, se reasigna el valor de las conexiones entre las neuronas, dándole más peso a las neuronas que tenían mayor importancia en la producción del resultado deseado, y otorgándole menor peso a las que tenían menor importancia. Esta red neuronal influenció a muchos desarrollos posteriores no sólo por sus posibilidades, si no también por sus limitaciones, especialmente  por su incapacidad de resolver problemas no lineales o que demanden recursividad, como diferenciar entre una C y una T rotadas, o diferenciar entre un número par y otro impar. Posteriores diseños de redes neuronales artificiales persiguieron el objetivo de solucionar estos problemas. Muchas de ellas lo lograron, y entre los 70 y los 80, se comenzaron a diseñar una cantidad innumerable de estas arquitecturas que poco a poco empezaron a darle forma a las redes neuronales artificiales o redes conexionistas.&lt;/p&gt;

&lt;p&gt;Si la vieja escuela consistía en la representación explícita del conocimiento, y la nueva escuela buscaba reconstruir los comportamientos inteligentes más básicos, el conexionismo persigue el objetivo de reconstruir los principios funcionales mediante los cuales opera el sistema nervioso central y poder representar de modo discreto sus procesos. Una consideración fundamental en este proyecto tiene su eje puesto en que las capacidades que estamos acostumbrados a considerar como formas de conocimiento, no se encuentran almacenadas en ciertos estados de un sistema, sino que más bien radican en la conexión global entre estos estados y las reglas que rigen entre dichas conexiones, que se van articulando mediante la experiencia. De esta manera, la premisa es la de abstraer las propiedades funcionales del cerebro e implementarlas en programas en una computadora. Los elementos que componen un sistema de este estilo pueden listarse en los siguientes ítems: un conjunto de unidades de procesamiento, un estado de activación (definido sobre las unidades de procesamiento), una función de output, un patrón de conectividad, una regla de activación, una regla de aprendizaje (que habilita a que los patrones de conectividad se modifiquen mediante la experiencia) y un entorno en el cual el sistema funciona. Las posibilidades que fueron demostrando estos sistemas entusiasmaron a algunos representantes de este área de investigación, que vieron en las redes neuronales la oportunidad de ir ascendiendo peldaño a peldaño en la construcción de sistemas artificiales que pudieran alcanzar este grado de complejidad y de operatividad de un sistema nervioso. Pero lo cierto es que no hizo y no hace falta que esto llegue a lograrse para que las redes neuronales den resultados interesantes o deseables en su aplicación. En este sentido, hablar de una inteligencia artificial propiamente dicha - sin negar la posibilidad de que eso exista o pueda existir - puede entenderse más bien como una mera metáfora.&lt;/p&gt;

&lt;p&gt;De esta breve historia de la inteligencia artificial que te estuvimos contando, es quizás ésta la más relevante para comprender muchos de los interesantes avances que vemos semana a semana, a los que tan difícil resulta seguirles el ritmo y que cada vez influencian más en casi todos los aspectos de nuestras vidas.&lt;/p&gt;

&lt;hr /&gt;
&lt;blockquote&gt;
  &lt;p&gt;La nota que acabás de leer fue escrita por Santiago López Gagliano, continuando con nuestra edición especial de verano sobre la historia de la inteligencia artificial. A continuación, te dejamos algunas referencias para ampliar la lectura de la nota:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Haugeland, J (1998) &lt;a href=&quot;https://mitpress.mit.edu/books/mind-design-ii&quot;&gt;Mind Design II: Philosophy, Psychology, Artificial Intelligence&lt;/a&gt;. MIT Press.&lt;/p&gt;

  &lt;p&gt;Una colección de algunos de los papers más importantes de la historia de la inteligencia artificial, con un especial hincapié en el conexionismo.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Rumelhart, D.E., J.L. McClelland (1986) &lt;a href=&quot;https://dl.acm.org/doi/book/10.5555/104279&quot;&gt;Parallel Distributed Processing: Explorations in the Microstructure of Cognition&lt;/a&gt;. Volume 1: Foundations. MIT Press.&lt;/p&gt;

  &lt;p&gt;Obra capital para comprender al conexionismo en todos sus aspectos, tanto desde la perspectiva de la inteligencia artificial, como en el resto de las aplicaciones que ha tenido en las ciencias cognitivas en general.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="ia" /><summary type="html">Redes neuronales, big data y la actualidad de la inteligencia artificial</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/ia_conexionismo.png" /><media:content medium="image" url="http://localhost:4000/ia_conexionismo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Inteligencia artificial: la nueva escuela</title><link href="http://localhost:4000/ia-nueva-escuela/" rel="alternate" type="text/html" title="Inteligencia artificial: la nueva escuela" /><published>2020-02-01T00:00:00+01:00</published><updated>2020-02-01T00:00:00+01:00</updated><id>http://localhost:4000/ia-nueva-escuela</id><content type="html" xml:base="http://localhost:4000/ia-nueva-escuela/">&lt;p&gt;&lt;a href=&quot;https://futurephilosophy.github.io/ia-vieja-escuela/&quot;&gt;En la nota anterior&lt;/a&gt; empezamos a contarte cuándo, dónde, y un poco acerca de cómo empezaron a construirse las primeras arquitecturas que le daban cuerpo al viejo sueño de construir una máquina que manifieste una inteligencia como la nuestra: la inteligencia artificial simbólica -o GOFAI-, que comenzó a mediados de los 50, se extendió a lo largo de los 60 y en los 70 empezó a manifestar sus limitaciones. También vimos la paradoja de Moravec que nos enseña mucho no sólo acerca de cuáles son las complicaciones a la hora de producir artificialmente una inteligencia como la nuestra, sino que también nos da pautas acerca de cómo autopercibimos nuestras habilidades, a qué tipos de capacidades solemos atribuirle complejidad e inteligencia, y cuales damos por sentadas.&lt;/p&gt;

&lt;p&gt;Con todo esto sobre la mesa, a mediados de los los 80 empezó a surgir una nueva camada de desarrolladorxs que inspirándose en los éxitos y fracasos de la “vieja escuela de la IA”, compusieron un nuevo núcleo de ideas e implementaciones tecnológicas que le han dado a llamar “&lt;a href=&quot;https://es.m.wikipedia.org/wiki/Nouvelle_AI&quot;&gt;nueva IA&lt;/a&gt;”. Este enfoque se propuso construir robots que, en vez de operar en micromundos limitados, pudieran afrontar las dificultades del mundo real, para lo cual, a diferencia de la GOFAI, dejaron de perseguir el diseño de inteligencia artificial como la manipulación de símbolos complejos, para entenderla más bien como la implementación de un conjunto de reglas muy sencillas que le permiten a un agente adaptarse de manera rápida y flexible. La premisa es que un robot, en vez de elaborar modelos internos de su mundo circundante, se base permanentemente en sus sensores que le muestran “lo que está ahí afuera”, actualizándose de forma constante a partir de la información recogida por ellos y estableciendo procesos que sean lo más minimalistas posibles, para poder adaptarse de forma plástica y dinámica al mundo circundante. Ya no se trata de que el robot  produzca modelos que “reemplacen” al mundo: es el mundo el que ofrece este modelo. Lo que tendrá que hacer un agente inteligente es adaptarse a él a partir de sus posibilidades físicas y computacionales.&lt;/p&gt;

&lt;p&gt;Para comprender un poco de qué se trató este cambio de dirección, pensemos en cuáles eran las inspiraciones que tomaban del mundo biológico: mientras que los desarrolladores de la GOFAI tenían el norte puesto en las operaciones lógico-matemáticas que un humano adulto es capaz de realizar, la nueva IA se fija en los comportamientos que característicamente vemos en insectos, como evitar obstáculos en movimiento, o trepar y agarrar objetos. Recordemos la paradoja de Moravec: aquellas capacidades más nuevas en el desarrollo evolutivo eran el punto de partida de la GOFAI; en cambio, la nueva IA decide seguir los pasos de la naturaleza, y empezar con los comportamientos más antiguos de la historia evolutiva. Dicho en otras palabras: la vieja IA empieza de “&lt;a href=&quot;https://es.m.wikipedia.org/wiki/Top-down_y_bottom-up&quot;&gt;arriba hacia abajo&lt;/a&gt;”, mientras que la nueva IA, de “&lt;a href=&quot;https://es.m.wikipedia.org/wiki/Top-down_y_bottom-up&quot;&gt;abajo hacia arriba&lt;/a&gt;”. Con esta estrategia se busca reconstruir los procesos que dan lugar a la inteligencia, en vez de dirigirse directamente hacia ella.&lt;/p&gt;

&lt;p&gt;Algunos de los representantes de esta camada fueron &lt;a href=&quot;https://www.edinburgh-robotics.org/academics/barbara-webb&quot;&gt;Barbara Webb&lt;/a&gt;, una de las pioneras de la Biorobótica, y &lt;a href=&quot;https://people.csail.mit.edu/brooks/&quot;&gt;Rodney Brooks&lt;/a&gt;, quien entre otras cosas fue el diseñador del prototipo de las aspiradoras-robot &lt;a href=&quot;https://es.m.wikipedia.org/wiki/Roomba&quot;&gt;Roomba&lt;/a&gt; y formó parte del diseño del &lt;a href=&quot;https://spaceplace.nasa.gov/mars-sojourner/sp/&quot;&gt;Róver Sojourner&lt;/a&gt;, un robot que pisó el suelo de Marte en 1997 como parte programa &lt;a href=&quot;https://www.nasa.gov/planetarymissions/discovery.html&quot;&gt;Discovery&lt;/a&gt; de la NASA.  Veamos de cerca algunos de los robots craneados por este último en el laboratorio de Inteligencia Artificial de MIT: &lt;a href=&quot;http://www.alanturing.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI11.html&quot;&gt;Allen&lt;/a&gt; -llamado así por &lt;a href=&quot;https://www.britannica.com/biography/Allen-Newell&quot;&gt;Allen Newell&lt;/a&gt;-  estaba compuesto por doce sondas ultrasónicas, que eran sus sensores principales. Estos sensores proporcionaban mediciones de profundidad a cada segundo. Esta información a su vez era capturada por tres módulos que eran independientes entre sí, pero cuya funcionalidad se encontraba relacionada. Uno de estos módulos se encargaba de que el robot evite colisionar con objetos, el segundo permitía que el robot deambulara, y el tercero garantizaba que el robot avanzara hacia objetos lejanos una vez que eran detectados por los sensores. Con este equipamiento, Allen logró interactuar con entornos complejos de forma exitosa. Si bien es cierto que su comportamiento distaba de igualar a las habilidades que exhibe un insecto biológico, significó un punto a favor de la idea de ir construyendo máquinas basadas en comportamientos elementales, que marquen una vía incremental de complejidad. Por otro lado, esto se logró sin apelar a representaciones explícitas del mundo; las operaciones computacionales de este robot no estaban puestas en construir un modelo interno del mundo circundante, si no en tener como referencia la data recibida por los sensores y hacerla interactuar con módulos productores de comportamiento de la forma más directa posible. De este modo, el robot puede ir actualizando su accionar en función de las novedades que le ofrece su entorno.&lt;/p&gt;

&lt;p&gt;Otro robot construido a partir de estas premisas fue &lt;a href=&quot;https://es.m.wikipedia.org/wiki/COG&quot;&gt;COG&lt;/a&gt;, un hito en la historia de los robots humanoides. A diferencia del ejemplo anterior, el proyecto COG tenía como target ciertas capacidades atribuibles a la inteligencia humana, pero lo hacía siguiendo el enfoque “desde abajo hacia arriba”. Es decir, buscando que la cognición emerja a partir de una serie de actividades más elementales, y con el menor peso posible en la elaboración de representaciones internas. COG disponía de cuatro estructuras sensibles al sonido, dos cámaras montadas en lo que vendría a ser su “cabeza”, detectores de tensión, calor y corriente, y conductores de energía eléctrica que le proporcionaban información táctil y propioceptiva. Sus mecanismos de movimiento constaban de un torso capaz de inclinarse y torcerse, un brazo y una mano. Una sofisticada integración entre sensores de distintas modalidades y los mecanismos de movimientos le permitió a COG emular algunos de los aspectos ligados al aprendizaje de categorías y de formación de conceptos que se observan en bebés humanos. Estos últimos aprenden de su entorno a partir de actividades motoras autogeneradas - como agarrar, empujar, jalar y chupar - que actúan como complemento para el procesamiento neuronal, guiando al flujo de información sensorial que reciben; de manera análoga, COG detectaba patrones rítmicos individuales y asociaba señales periódicas gracias a la implementación de un algoritmo de enlace. A partir de dichos enlaces, COG podía aprender sobre sus propias partes del cuerpo, pudiendo incluso dar muestras de reconocer la imagen de su propio brazo en el espejo.&lt;/p&gt;

&lt;p&gt;Son muchos los ámbitos de aplicación que la nueva IA tiene y ha tenido. Algunos de ellos son la agricultura, la automatización laboral, los servicios de salud, el desarrollo militar, y tareas domésticas, entre otros. Sin lugar a dudas, veremos muchas más aplicaciones en los próximos años y en niveles que muy posiblemente nos sorprenderían hoy por hoy. Y aunque la cultura pop (con Hollywood a la cabeza) en muchos casos nos ha educado para tenerle cierta fobia a este campo de desarrollo tecnológico, quizás ya sería hora de que le perdamos el miedo a los robots, comprendiendo cuales son los principios de sus diseños, sus posibilidades, sus limitaciones y cuál podría ser nuestra incidencia en garantizar que estos escenarios distópicos no se produzcan. Ciertamente, una mirada frívola, acrítica y tecnofóbica no darán como resultado una respuesta efectiva a este problema.&lt;/p&gt;

&lt;hr /&gt;
&lt;blockquote&gt;
  &lt;p&gt;En esta nota continuamos con nuestra edición especial de verano, dedicada a la historia de la inteligencia artificial, esta vez con las nuevas tendencias que le siguieron a su paradigma inicial en la conferencia de Dartmouth. Te dejamos algunos links para ampliar la lectura:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Pfeifer, R. &amp;amp; Bongard, J (2007). &lt;a href=&quot;https://mitpress.mit.edu/books/how-body-shapes-way-we-think&quot;&gt;How the Body Shapes the Way We Think A New View of Intelligence&lt;/a&gt;.  MIT Press&lt;/p&gt;

  &lt;p&gt;Este libro es una referencia ineludible para comprender aspectos de biorobótics y sus implicaciones filosóficas. También ofrece una taxonomía bastante completa de los tipos de robots que en un futuro no muy lejano podrían acompañarnos en nuestro día a día.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Brooks, R (1999). &lt;a href=&quot;https://mitpress.mit.edu/books/cambrian-intelligence&quot;&gt;Cambrian Intelligence: The Early History of the New AI&lt;/a&gt;. MIT Press.&lt;/p&gt;

  &lt;p&gt;Todas las ideas principales acerca de la nueva IA están desarrolladas en este compendio de papers escritos por Rodney Brooks. En el podemos observar los primeros pasos de este enfoque, y su ulterior evolución.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Clark, A (2007). &lt;a href=&quot;https://global.oup.com/academic/product/supersizing-the-mind-9780195333213?cc=us&amp;amp;lang=en&amp;amp;&quot;&gt;Supersizing the Mind&lt;/a&gt;. MIT Press.&lt;/p&gt;

  &lt;p&gt;Esta obra filosófica integra aspectos de ciencias cognitivas, filosofía de la mente, neurociencias e inteligencia artificial en una perspectiva integral acerca de la cognición humana en particular, y animal en general. Algunos casos de la robótica del paradigma de la nueva IA le sirven al autor para ilustrar ejemplos y elaborar argumentos en favor de sus tesis.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Webb, B (2001). &lt;a href=&quot;https://www.aaai.org/Press/Books/webb.php&quot;&gt;Biorobotics: Methods and Applications&lt;/a&gt;. AAAI Pres.&lt;/p&gt;

  &lt;p&gt;Otra minuciosa exploración en el mundo de la biorobótica por parte de Barbara Webb, una de las maestras en el área. En esta obra demuestra cómo la robótica puede funcionar para construir modelos científicos que expliquen el comportamiento de animales biológicos.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="ia" /><summary type="html">Nueva inteligencia artificial, robótica y corporalidad</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/ia_nueva_escuela.png" /><media:content medium="image" url="http://localhost:4000/ia_nueva_escuela.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Inteligencia artificial: la vieja escuela</title><link href="http://localhost:4000/ia-vieja-escuela/" rel="alternate" type="text/html" title="Inteligencia artificial: la vieja escuela" /><published>2020-01-25T00:00:00+01:00</published><updated>2020-01-25T00:00:00+01:00</updated><id>http://localhost:4000/ia-vieja-escuela</id><content type="html" xml:base="http://localhost:4000/ia-vieja-escuela/">&lt;p&gt;Nuestra obsesión por construir una máquina que se mueva, piense, reaccione y se exprese como nosotros no es para nada nueva. Antecedentes de esta peculiar inquietud podemos rastrearlos en los autómatas de Pierre Jaquet-Droz en el siglo XVIII. Pero recién en el siglo XX comenzamos a poseer las herramientas tecnológicas, técnicas, ingenieriles y computacionales como para que la ilusión de concretar esta empresa parezca más probable o, como mínimo, menos improbable. Fueron innumerables los intentos para empezar a construir los bloques indispensables de este ambicioso proyecto, con diseños que exhibieron diversas estructuras, tamaños y comportamientos. Pero centrémonos en dos casos paradigmáticos: los robots &lt;a href=&quot;https://en.wikipedia.org/wiki/Freddy_II&quot;&gt;Freddy&lt;/a&gt; y &lt;a href=&quot;https://en.wikipedia.org/wiki/Shakey_the_robot&quot;&gt;Shakey&lt;/a&gt; del Departamento de Inteligencia Artificial de la Universidad de Edimburgo y del Instituto de Investigación de Stanford respectivamente.&lt;/p&gt;

&lt;p&gt;Freddy fue el modelo de un robot estático –del cual existieron dos réplicas: Freddy y Freddy II– que existió entre los años 1969 y 1976 y estaba por compuesto por dos cámaras que simulaban a los ojos, y una estructura mecánica que simulaba el accionar de una mano. Estos robots funcionaban a partir de la integración de dos computadoras, cuyos programas perseguían el objetivo de que Freddy “reconociera” ciertos objetos, reaccionara acorde a ellos según diversas situaciones que se le presentaban y diversos objetivos que se le prescribían como, por ejemplo, ubicar algunas piezas geométricas dentro de una caja. Shakey, por su parte, existió entre los años 1966 y 1972 y fue un robot que, a diferencia de Freddy y Freddy II, era móvil, y esto le permitía interactuar de manera más dinámica con entornos que estaban diseñados con el fin de testear su desempeño. Estos entornos estaban compuestos de objetos tales como paredes, puertas y bloques de madera. Algunas de las tareas que Shakey realizaba era mover los bloques de un lugar a otro sin intervención humana, siguiendo un detallado plan de acción que consistía en secuencias de  programación previamente dispuestas. Si bien las tareas que debían realizar Shakey y Freddy eran relativamente sencillas, sus desempeños significaron un avance notable para la época.&lt;/p&gt;

&lt;p&gt;Para entender el paradigma a partir del cual operaban, deben introducirse los conceptos de “&lt;a href=&quot;https://en.wikipedia.org/wiki/History_of_artificial_intelligence#Micro-worlds&quot;&gt;micromundos&lt;/a&gt;” y la “&lt;a href=&quot;https://en.wikipedia.org/wiki/Physical_symbol_system&quot;&gt;hipótesis de los sistemas simbólicos&lt;/a&gt;”: el primero de estos conceptos fue introducido por Marvin Minsky, uno de los participantes de la Conferencia de Dartmouth (de donde nació la disciplina de la Inteligencia Artificial) y Seymour Papert, un matemático que trabajó en lenguajes de programación y psicología del desarrollo. Esta idea consiste en que el desarrollo de sistemas artificiales inteligentes debe contar con la elaboración de entornos simplificados y restringidos, algo así como “bloques de mundo” en los cuales dichos sistemas artificiales puedan interactuar de forma concreta y sin grandes dificultades. Por su parte, la “hipótesis de los sistemas simbólicos” de Newell y Simon - que también formaron parte de la Conferencia de Dartmouth - se basaba en la convicción  de que la mejor manera de reproducir comportamientos inteligentes como los que exhibe el ser humano –tareas tales como realizar operaciones matemáticas, jugar al ajedrez o entender y elaborar oraciones– tiene que basarse en la manipulación de secuencias simbólicas dado que, de hecho, esta es la forma con la que opera la inteligencia humana. Dicho de modo muy resumido: para estos investigadores, tenemos símbolos codificados en el cerebro, y las operaciones mentales son las que se encargan de vincular estos símbolos entre sí para producir expresiones a partir de una serie de reglas sintácticas. Una computadora que intente emular la inteligencia humana, por tanto, tendrá que contar con elementos análogos: la diferencia es que en vez de símbolos codificados en el cerebro, poseerá datos codificados en un programa.&lt;/p&gt;

&lt;p&gt;Estas dos nociones fueron parte del derrotero de los orígenes de la Inteligencia Artificial que posteriormente sería denominado &lt;a href=&quot;https://es.wikipedia.org/wiki/Inteligencia_artificial_simb%C3%B3lica&quot;&gt;GOFAI&lt;/a&gt; (Good Old Fashioned Artificial Intelligence) y entre la década del 50 y los 70, marcó el clima de desarrollo de una disciplina científica incipiente que prometía muchos avances y que, en los casos más exagerados, proponía pronósticos desmedidos en los que se calculaba que en menos de 10 o 15 años se podría llegar a emular todos los aspectos fundamentales de la inteligencia humana. Ciertamente no faltaban razones para entusiasmarse: hacía tan sólo algunos años atrás, las computadoras eran artefactos que podían llevar a cabo tareas aritméticas complejas, pero no mucho más que eso. De pronto, un boom de desarrollos tecnológicos marcó la pauta de que se podía lograr que una computadora exhibiera comportamientos que pueden considerarse, de un modo u otro, como inteligentes. Programas de comprensión del lenguaje natural como el histórico SHRDLU, de Terry Winograd o programas de resolución de problemas como el SRGP de Newell y Simon eran claros ejemplos de esto. McCarthy –otro de los pioneros de la Inteligencia Artificial– denominó, con cierto humor, a este boom como la época del “Mira, mamá, ahora sin manos!”.&lt;/p&gt;

&lt;p&gt;Pero todo este entusiasmo originario pronto comenzó a desinflarse. La cruda realidad demostró que, si bien se había descubierto una veta interesante, la cosa era mucho más complicada de lo que parecía. En el caso puntual de la robótica, aún siendo que estábamos ante un panorama de arquitecturas tecnológicas inéditas, lo cierto es que la posibilidad de que éstas exhibieran los comportamientos flexibles, dinámicos y adaptativos que caracterizan a los animales humanos y no humanos, se encontraba aún a una distancia de concreción muy grande. En el caso de nuestros amigos Freddy y Shakey, las limitaciones eran claras. Freddy lograba sin muchas dificultades poner los objetos dentro de la caja; el problema es que cuando terminaba de agarrar todos los objetos, agarraba también a la caja misma y la soltaba al aire, demostrando que algunas de las intuiciones básicas que operan en el comportamiento animal inteligente no estaban pudiendo ser representadas. Shakey, por su parte, lograba realizar ciertas acciones como llevar un objeto de punto ‘a’ al punto ‘b’, superando obstáculos de por medio. Pero lo hacía con una lentitud notable, tomando a veces días enteros hasta completar la operación. Muchos otros diseños robóticos de la época demostraban restricciones análogas. Cuando se intentaba hacerlos interactuar por fuera de los micromundos, manifestaban una motricidad rígida, una movilidad y adaptabilidad a obstáculos muy limitadas, bloqueos en su accionar o formas de solucionar problemas que no se asemejan a los modos que solemos ver en el comportamiento animal. Todos estos problemas le abrieron los ojos a los padres de la IA, que comenzaron a observar que los presupuestos implícitos en esta disciplina permitían desarrollar programas que tenían un relativo éxito a la hora de realizar tareas abstractas que realiza un humano adulto, pero muy poco éxito a la hora de emular comportamientos sensorio-motrices básicos, como agarrar un objeto o moverse de modo adecuado. O como se ha dicho en ciertas ocasiones: eran sistemas buenos para las matemáticas, pero malos para el fútbol.&lt;/p&gt;

&lt;p&gt;Este problema fue observado con pericia por otro importante personaje en la historia de la IA: Hans Moravec. El diagnóstico de este desarrollador era que aquellas tareas que se consideraban más complejas y sofisticadas, son las que requieren menores procesos computacionales, mientras que las que parecían ser capacidades más sencillas, son las que más esfuerzo demandan a la hora de emular. Una de las intuiciones que operan detrás de esta paradoja –llamada “paradoja de Moravec”– es que las habilidades sensorio-motrices son las más ancestrales a nivel evolutivo y, por tanto, como especie, poseemos una gran experiencia realizándolas y esto hace que las demos por sentadas, haciendo parecer fácil lo que en verdad es difícil. En cambio, las capacidades, más abstractas, que pueden entenderse dentro de la esfera del razonamiento, son las más recientes a nivel evolutivo; y al ser las más recientes, no las hemos dominado del todo aún, y es por eso mismo mismo que tendemos a pensar que son las capacidades más difíciles de todas. Pero es muy posible que éstas no sean difíciles per se: sólo nos parece que lo son, porque nos cuesta mucho más esfuerzo llevarlas a cabo.&lt;/p&gt;

&lt;p&gt;La implementación de estos mecanismos en sistemas artificiales nos ofrece la lección de que el esfuerzo para emular las capacidades que manifiestan agentes biológicos es directamente proporcional al tiempo que dichas capacidades tomaron para evolucionar. Por ende, será esperable que las capacidades que parecen ser sencillas y que no demandan mucho esfuerzo, sean las más difíciles de emular, y viceversa. La paradoja de Moravec marcó un antes y un después en la historia de la Inteligencia Artificial, influenciando a toda una generación posterior de científicxs, ingenierxs, y diseñadorxs del campo y sigue teniendo su relevancia al día de la fecha.&lt;/p&gt;

&lt;hr /&gt;
&lt;blockquote&gt;
  &lt;p&gt;Esta nota inaugura una edición especial de verano sobre la historia de la inteligencia artificial y sus desarrollos contemporáneos. A diferencia de nuestras ediciones anteriores, vamos a estar mandándote un mail todos los sábados contándote esta historia. Quedate atentx para saber qué pasó con la inteligencia artificial luego de Dartmouth. Para ampliar la lectura, te dejamos algunos datos más y textos para consultar.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;La &lt;strong&gt;conferencia de Dartmouth&lt;/strong&gt; que se menciona en esta nota fue un encuentro realizado en el año 1956 en la universidad Dartmouth College. En ella, varios científicos e investigadores de áreas como las matemáticas, las ciencias de la computación y la ingeniería electrónica, entre otras, sentaron las bases de esta disciplina, que inspirándose en la obra de Turing, aspectos de la teoría de autómatas, la teoría de la información y la cibernética, comenzó a vislumbrar la posibilidad de construir máquinas que piensen. Además de las personalidades nombradas en esta nota, en dicha conferencia participaron Claude Shannon, W.S. McCulloch, W. Ross Ashby, Julian Bigelow y Ray Solomonoff, entre otros.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Norvig, P. y Russell, S. (1994) &lt;a href=&quot;https://www.pearsoneducacion.net/espa%C3%B1a/TiendaOnline/inteligencia-artificial-un-enfoque-moderno-2ed&quot;&gt;Inteligencia Artificial&lt;/a&gt;: Un Enfoque Moderno. Prentice Hall&lt;/p&gt;

  &lt;p&gt;Este es posiblemente el manual más completo que exista en materia de IA. Tiene una muy buena introducción acerca de la historia de esta disciplina y mucha información técnica de utilidad tanto para quienes tienen mucha experiencia, como para quienes recién están arrancando a aventurarse en el mundo de la programación.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moravec, H. (1988). &lt;a href=&quot;https://www.hup.harvard.edu/catalog.php?isbn=9780674576186&quot;&gt;Mind Children&lt;/a&gt;. Harvard University Press&lt;/p&gt;

  &lt;p&gt;En esta obra, Hans Moravec especula con la idea de que entre la década del 2030 y el 2040 podremos ser capaces de construir robots que alcancen niveles de complejidad mucho más sofisticados que los que vemos al día de la fecha. Más allá de estar de acuerdo con sus predicciones o no, ofrece puntos de partida muy interesantes para comprender aspectos importantes acerca de la paradoja de Moravec, ley de Moore, la robótica y la vida artificial.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Haugeland, J. (1986) &lt;a href=&quot;https://www.hup.harvard.edu/catalog.php?isbn=9780674576186&quot;&gt;Artificial Intelligence&lt;/a&gt;: The Very Idea. MIT Press&lt;/p&gt;

  &lt;p&gt;John Haugeland fue un pensador que encarnó de manera muy audaz la figura del filósofo comprometido en materia tecnológica. En este libro desarrolla muchos de los problemas principales de la IA, tocando temas de filosofía de la mente, ciencias cognitivas y fenomenología. La idea de identificar y definir la primera etapa de la IA como “GOFAI” fue de él y se encuentra en esta pieza filosófica.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="ia" /><summary type="html">Los primeros pasos de la inteligencia artificial simbólica</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/ia_vieja_escuela.png" /><media:content medium="image" url="http://localhost:4000/ia_vieja_escuela.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">El mito de la realidad virtual</title><link href="http://localhost:4000/mito_realidad_virtual/" rel="alternate" type="text/html" title="El mito de la realidad virtual" /><published>2020-01-11T00:00:00+01:00</published><updated>2020-01-11T00:00:00+01:00</updated><id>http://localhost:4000/mito_realidad_virtual</id><content type="html" xml:base="http://localhost:4000/mito_realidad_virtual/">&lt;p&gt;Muchxs de nosotrxs escuchamos alguna vez la idea de que, con el desarrollo y la difusión de la realidad virtual, existe la posibilidad de que nos veamos cada vez más inmersos en esta tecnología, y que pase a formar una parte cada vez más integral de nuestras vidas. La idea ya es moneda corriente en la ciencia ficción, siendo un claro ejemplo el tan citado libro de William Gibson, Neuromancer, en donde Case, el protagonista de la novela, desdeña su vida corpórea fuera de la realidad virtual, y en cambio preferiría pasar su tiempo íntegramente allí.&lt;/p&gt;

&lt;p&gt;Esta idea tiene quizás demasiadas consecuencias para analizarlas todas en este espacio. Sin embargo, una de las primeras dudas que suscita es si se trata de un problema genuinamente filosófico, o si en realidad merece ser considerado como un escenario que hasta ahora parece demasiado lejano, inverosímil. En los tratamientos filosóficos de la &lt;em&gt;virtualidad&lt;/em&gt;, lo que ahora conocemos como realidades virtuales son sólo un caso de un fenómeno mayor que es la virtualidad: cualquier artefacto o tecnología que, en algún sentido, duplica nuestra realidad, agregándole una capa de abstracción con nuevas dinámicas de comunicación y difusión de la información, puede ser considerada virtual. Según esta definición, hasta el lenguaje caería bajo esta categoría. Si bien las actuales realidades virtuales prometen un nivel de inmersión que permite reemplazar muchas de las fuentes de experiencia sensorial por otras computacionalmente generadas, sin embargo podemos suponer que este no sería más que un caso extremo de un fenómeno que ya viene sucediendo, y que por lo tanto merece la atención del trabajo filosófico.&lt;/p&gt;

&lt;p&gt;De todos modos, la idea misma ha recibido muchas críticas. En su libro &lt;em&gt;Program or Be Programmed&lt;/em&gt;, Douglas Rushkoff presenta algunas sugerencias para la vida en la época de la interconexión masiva y los dispositivos móviles. Entre ellas se encuentra la idea de no estar siempre conectadx a un dispositivo, y el hecho de vivir en persona, o no dejar de priorizar las interacciones físicas. Además, puede trazarse una analogía entre ciertas consecuencias que esta idea trae y una de las tesis principales del transhumanismo: llegará un punto en el desarrollo tecnológico en el que las personas pasarán a considerar la muerte como una enfermedad curable. Esto entra en contradicción con otra idea fundamental del trabajo filosófico de Martin Heidegger, según el cual la muerte, representante principal de la finitud y por lo tanto de la temporalidad, es la característica fundamental de todo existente. Veamos con mayor detalle cada una de estas críticas.&lt;/p&gt;

&lt;h2 id=&quot;la-dependencia-tecnológica&quot;&gt;La dependencia tecnológica&lt;/h2&gt;

&lt;p&gt;En el momento en que decidimos realizar una tarea de nuestra cotidianeidad por medio de un artefacto cualquiera, permitimos que este objeto adquiera una importancia fundamental en nuestras vidas: nos volvemos, en buena medida, dependientes. No sólo del buen funcionamiento de este aparato, sino además dependientes de las empresas que los producen acorde a sus propios beneficios. Dependientes, también, de las corrientes y modas del desarrollo industrial, entregándonos al frenesí del avance técnico. Este fenómeno no es nuevo, sino que ya podemos experimentarlo en nuestro uso de celulares, o incluso de la luz eléctrica. Pero podemos sospechar que en el caso de algo tan abarcador como podría ser la realidad virtual para nuestras vidas, las consecuencias se vuelven más peligrosas, ya que quedaríamos a merced de las empresas que manejan estas tecnologías, a la vez de ser fuentes de información excesivamente personal, como la manera en la que percibimos.&lt;/p&gt;

&lt;p&gt;Así, las dos sugerencias que Rushkoff ofrece para recuperar nuestra vida “real” se volverían casi imposibles de cumplir. En el escenario que estamos imaginando, desconectarse de nuestros dispositivos implicaría alejarnos de muchas de nuestras actividades cotidianas, como la socialización o el movimiento por una ciudad. Efectivamente, no estaríamos viviendo en persona, sino en la simulación. Pero quizás la respuesta a esta dificultad viene dada en el mismo título del texto citado, que introduce la última de las sugerencias del texto: programar o ser programado. La idea es que podríamos desarrollar una relación mucho más autónoma con la tecnología que la posición pasiva que supone  ser un usuario de los artefactos y aplicaciones que nos ofrecen. Si decidiéramos vivir en realidades virtuales podríamos también entender cómo están programadas, superar el encapsulamiento de su andamiaje y de esa forma interactuar de una manera más entendida y también responsable.&lt;/p&gt;

&lt;p&gt;En esta línea, existen actualmente iniciativas dentro del movimiento de tecnologías libres que buscan democratizar el desarrollo tanto de software como de hardware vinculado a las realidades virtuales. Un proyecto destacado en este marco es el llamado &lt;a href=&quot;http://www.osvr.org/&quot;&gt;Open Source Virtual Reality&lt;/a&gt; (OSVR), que ofrece tanto una plataforma para desarrollar material audiovisual como para correr material ya existente, y además tiene disponibles los &lt;a href=&quot;https://github.com/OSVR/OSVR-HDK&quot;&gt;diseños de su visor&lt;/a&gt;. De esta forma, el objetivo que buscan es achicar la brecha entre el usuario final y los desarrolladores.&lt;/p&gt;

&lt;h2 id=&quot;los-roles-del-cuerpo&quot;&gt;Los roles del cuerpo&lt;/h2&gt;

&lt;p&gt;Uno de los aspectos principales de la realidad virtual tal como es presentada en Neuromancer es el hecho de que, una vez dentro de ella, los límites del espacio y el tiempo son redefinidos. Nuevamente, se trata de un fenómeno que ya nos es considerablemente familiar: no es necesaria la presencia física para interactuar con otra persona, ni es necesario esperar meses para mandar un mensaje al otro lado del mundo. El problema surge cuando, luego de una prolongada exposición a estas dinámicas, y particularmente en un entorno plenamente inmersivo en donde nos acercamos a olvidar lo que es el mundo ahí afuera, podemos tener dificultades para volver. O incluso más, podemos empezar a desdeñar las viejas dinámicas espaciales y temporales de lo “real”. Podemos pensar en los hikikomori, personas (usualmente jóvenes japoneses) que deciden retirarse al confinamiento de sus habitaciones como resultado de la agorafobia o una timidez extrema, y que en muchos casos terminan relegando sus vínculos al exterior por medios virtuales, llevándolos a vivir en condiciones de abandono del cuerpo.&lt;/p&gt;

&lt;p&gt;La redefinición de las dinámicas en la comunicación y la transferencia de información en términos de nuevos entramados espaciotemporales no parece ser, a primera vista, problemática. Si bien personas como el anteriormente citado Rushkoff consideran que esto trae consecuencias poco deseables, también pueden pensarse muchas otras que son sin duda deseables, y que no es claro que no debamos abrazarlas. Pero cuando alcanzamos ese punto en donde comenzamos a preferir permanecer en ese entorno, corremos el riesgo de abandonar algunas de las estructuras que nos caracterizan en tanto existentes. Para Heidegger, aquello que caracteriza en un sentido más profundo nuestra existencia es el hecho de que vamos a morir. Es decir, la marca del modo de ser de un existente cualquiera es su finitud, y en este sentido la temporalidad se vuelve la característica central del ser de todos los entes.&lt;/p&gt;

&lt;p&gt;Es difícil imaginar un modo en que dichas limitaciones pudieran ser superadas gracias a los desarrollos de la tecnología. Un desarrollo orientado en esta dirección es el llamado &lt;em&gt;mind-uploading&lt;/em&gt;, cuyo objetivo es alcanzar la capacidad de almacenar la mente completa de una persona en una computadora. Pese a la existencia de iniciativas que pretenden dar con esta tecnología, por ahora no parecemos estar cerca de lograr algo parecido. Éste sería otro desarrollo cuyas consecuencias filosóficas serían muy vastas y profundas, pero que dado nuestro estadío actual, permanece como un problema de ficción.&lt;/p&gt;

&lt;p&gt;En pocas palabras, la conclusión principal que podemos extraer de esta discusión es que la realidad virtual, como modelo de las tecnologías de la comunicación y la información, trae adjuntas una serie de críticas que, sin embargo, pueden ser respectivamente contestadas. Pero esto no implica que, llegado el momento en que esta tecnología estuviese adecuadamente desarrollada, deberíamos entregarnos plenamente a su utilización. Por el contrario, existen aspectos intrínsecos a nuestro modo de existir que siempre tendremos que atender y recordar. Como le diría el tío Ben al hombre araña: “un gran poder conlleva una gran responsabilidad”.&lt;/p&gt;

&lt;hr /&gt;
&lt;blockquote&gt;
  &lt;p&gt;Algunos links para complementar la lectura&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Gibson, W. (1984). &lt;a href=&quot;https://www.penguinrandomhouse.com/books/293994/neuromancer-by-william-gibson/&quot;&gt;Neuromancer&lt;/a&gt;. Nueva York, Ace Books.&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Esta novela fue la iniciadora del movimiento conocido como ciberpunk. En ella, se presenta un futuro distópico en el que Case, un joven hacker, tendrá que realizar una serie de trabajos para prevenir que una bolsa con químicos instalada en su cerebro explote, provocándole la disolución de aquellas proteínas que codifican su talento como programador. Además de ser una historia atrapante y excelentemente escrita, incluye una de las primeras presentaciones de una realidad virtual como la que se discutió en este texto, y está plagada de momentos en que los personajes se debaten problemas filosóficos relacionados a los avances tecnológicos, que dejan abiertos para que el lector medite.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Rushkoff, D. (2010). &lt;a href=&quot;https://rushkoff.com/books/program-or-be-programmed/&quot;&gt;Program or Be Programmed&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Douglas Rushkoff nos ofrece una serie de sugerencias para la era digital. El objetivo general de su libro apunta a tener una mirada más crítica frente a las tecnologías de la comunicación y la información, a partir de la cual nos concienticemos acerca de las dinámicas que se nos busca imponer para luego tomar la decisión sobre si queremos seguirlas o no.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;El &lt;strong&gt;transhumanismo&lt;/strong&gt; es un movimiento filosófico con múltiples vertientes. &lt;a href=&quot;https://whatistranshumanism.org/&quot;&gt;Acá&lt;/a&gt; podés leer un poco más de qué se trata. Un filósofo destacado dentro de este movimiento es &lt;a href=&quot;https://nickbostrom.com/&quot;&gt;Nick Bostrom&lt;/a&gt;, director del &lt;a href=&quot;https://www.fhi.ox.ac.uk/&quot;&gt;Instituto para el Futuro de la Humanidad&lt;/a&gt;, y autor de varios libros sobre la Inteligencia Artificial y el transhumanismo.&lt;/p&gt;

  &lt;p&gt;Por último, la filosofía de &lt;strong&gt;Martin Heidegger&lt;/strong&gt; es difícil de presentar en este espacio. Una de sus obras principales es &lt;a href=&quot;http://www.afoiceeomartelo.com.br/posfsa/Autores/Heidegger,%20Martin/Heidegger%20-%20Ser%20y%20tiempo.pdf&quot;&gt;Ser y Tiempo&lt;/a&gt; (1927), en la cual propone el concepto de “ser para la muerte” como aquel en que se encarna su postura acerca de la temporalidad y la existencia. Si leés en inglés, acá vas a encontrar una introducción muy completa y detallada de sus ideas.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="tecnología" /><summary type="html">Desmitificando algunos de los más grandes prejuicios sobre la realidad virtual.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/mito_realidad_virtual.png" /><media:content medium="image" url="http://localhost:4000/mito_realidad_virtual.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>